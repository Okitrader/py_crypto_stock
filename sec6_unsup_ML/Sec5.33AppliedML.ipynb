{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f5abd8-921a-4e3e-aa80-37ee6c204726",
   "metadata": {},
   "source": [
    "# Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a837c4a-ec38-49e7-8984-6161913d7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Management\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from pandas_datareader.data import DataReader\n",
    "from ta import add_all_ta_features\n",
    "\n",
    "#Statistics\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "#Data Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "# Supervised Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Reporting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767552d-8a2c-4c44-987d-8639324af379",
   "metadata": {},
   "source": [
    "# Data Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35172e61-ef5c-4463-811c-8d7a48c8a7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Data: 199504\n",
      "shape: (5, 9)\n",
      "┌────────────┬─────┬──────────────┬────────────┬───┬─────┬──────┬─────┬──────────┐\n",
      "│ Date       ┆ Id  ┆ suburb       ┆ postalCode ┆ … ┆ bed ┆ bath ┆ car ┆ propType │\n",
      "│ ---        ┆ --- ┆ ---          ┆ ---        ┆   ┆ --- ┆ ---  ┆ --- ┆ ---      │\n",
      "│ str        ┆ i64 ┆ str          ┆ i64        ┆   ┆ f64 ┆ i64  ┆ f64 ┆ str      │\n",
      "╞════════════╪═════╪══════════════╪════════════╪═══╪═════╪══════╪═════╪══════════╡\n",
      "│ 2019-06-19 ┆ 1   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 4.0 ┆ 2    ┆ 2.0 ┆ house    │\n",
      "│ 2019-06-13 ┆ 2   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 4.0 ┆ 3    ┆ 4.0 ┆ house    │\n",
      "│ 2019-06-07 ┆ 3   ┆ Whale Beach  ┆ 2107       ┆ … ┆ 3.0 ┆ 3    ┆ 2.0 ┆ house    │\n",
      "│ 2019-05-28 ┆ 4   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 3.0 ┆ 1    ┆ 2.0 ┆ house    │\n",
      "│ 2019-05-22 ┆ 5   ┆ Whale Beach  ┆ 2107       ┆ … ┆ 5.0 ┆ 4    ┆ 4.0 ┆ house    │\n",
      "└────────────┴─────┴──────────────┴────────────┴───┴─────┴──────┴─────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Set the file path\n",
    "file_path = \"/Users/okitrader/OneDrive/py_crypto_stock/SydneyHousePrices.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "df = pl.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(f'Length of Data: {len(df)}')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05bccfed-cdc6-4473-a1cc-3597649efddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Id', 'suburb', 'postalCode', 'sellPrice', 'bed', 'bath', 'car', 'propType']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b229bd14-d5a8-4e51-b5df-43562e482a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "OrderedDict({'Date': String, 'Id': Int64, 'suburb': String, 'postalCode': Int64, 'sellPrice': Int64, 'bed': Float64, 'bath': Int64, 'car': Float64, 'propType': String})\n",
      "\n",
      "Number of rows: 199504\n",
      "Number of columns: 9\n",
      "\n",
      "Null counts for each column:\n",
      "shape: (1, 9)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ Date_null ┆ Id_null_c ┆ suburb_nu ┆ postalCod ┆ … ┆ bed_null_ ┆ bath_null ┆ car_null_ ┆ propType │\n",
      "│ _count    ┆ ount      ┆ ll_count  ┆ e_null_co ┆   ┆ count     ┆ _count    ┆ count     ┆ _null_co │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ unt       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ unt      │\n",
      "│ u32       ┆ u32       ┆ u32       ┆ ---       ┆   ┆ u32       ┆ u32       ┆ u32       ┆ ---      │\n",
      "│           ┆           ┆           ┆ u32       ┆   ┆           ┆           ┆           ┆ u32      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 0         ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 154       ┆ 0         ┆ 18151     ┆ 0        │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame schema\n",
    "print(\"Schema:\")\n",
    "print(df.schema)\n",
    "\n",
    "# Display number of rows and columns\n",
    "print(\"\\nNumber of rows:\", df.height)\n",
    "print(\"Number of columns:\", df.width)\n",
    "\n",
    "# Display null counts for each column\n",
    "print(\"\\nNull counts for each column:\")\n",
    "null_counts = df.select([pl.col(col).is_null().sum().alias(f\"{col}_null_count\") for col in df.columns])\n",
    "print(null_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc7df1-598d-4dfb-babc-10f74a3d4219",
   "metadata": {},
   "source": [
    "# Feature Engineering - Common Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bf2bb-31d9-47be-a0a0-19f2f131b1ad",
   "metadata": {},
   "source": [
    "## Handle Non-Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95ee72a-0333-477a-85e5-07af74893c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Suburbs:  685\n",
      "Preform label encoding\n"
     ]
    }
   ],
   "source": [
    "# Count unique items for 'suburb'\n",
    "suburb_text_unique = df['suburb'].unique()\n",
    "suburb_text_unique_list = suburb_text_unique.to_list() # prints the full list for viewing\n",
    "print('Unique Suburbs: ', len(suburb_text_unique))\n",
    "print('Preform label encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06dde192-8fbe-4890-b4d5-cf4c247b659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Prop Types:  8\n",
      "Preform OneHotEncoding encoding\n"
     ]
    }
   ],
   "source": [
    "# Count unique items for propType\n",
    "prop_type_text_unique = df['propType'].unique()\n",
    "print('Unique Prop Types: ', len(prop_type_text_unique))\n",
    "print('Preform OneHotEncoding encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1603cb80-5331-48c6-bdd7-3301b5f243c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 10)\n",
      "┌────────────┬─────┬──────────────┬────────────┬───┬──────┬─────┬──────────┬─────────────────┐\n",
      "│ Date       ┆ Id  ┆ suburb       ┆ postalCode ┆ … ┆ bath ┆ car ┆ propType ┆ suburbs_encoded │\n",
      "│ ---        ┆ --- ┆ ---          ┆ ---        ┆   ┆ ---  ┆ --- ┆ ---      ┆ ---             │\n",
      "│ str        ┆ i64 ┆ str          ┆ i64        ┆   ┆ i64  ┆ f64 ┆ str      ┆ u32             │\n",
      "╞════════════╪═════╪══════════════╪════════════╪═══╪══════╪═════╪══════════╪═════════════════╡\n",
      "│ 2019-06-19 ┆ 1   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 2    ┆ 2.0 ┆ house    ┆ 22              │\n",
      "│ 2019-06-13 ┆ 2   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 3    ┆ 4.0 ┆ house    ┆ 22              │\n",
      "│ 2019-06-07 ┆ 3   ┆ Whale Beach  ┆ 2107       ┆ … ┆ 3    ┆ 2.0 ┆ house    ┆ 654             │\n",
      "│ 2019-05-28 ┆ 4   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 1    ┆ 2.0 ┆ house    ┆ 22              │\n",
      "│ 2019-05-22 ┆ 5   ┆ Whale Beach  ┆ 2107       ┆ … ┆ 4    ┆ 4.0 ┆ house    ┆ 654             │\n",
      "└────────────┴─────┴──────────────┴────────────┴───┴──────┴─────┴──────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding for 'suburb'\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Perform label encoding on the 'suburb' column to convert categorical text data into numerical values\n",
    "# The LabelEncoder's fit_transform method fits the encoder and returns the transformed values as a NumPy array\n",
    "# This step is necessary for machine learning models which require numerical input data\n",
    "encoded_suburbs = labelencoder.fit_transform(df['suburb'].to_numpy())\n",
    "\n",
    "\n",
    "# Add the encoded column to the DataFrame\n",
    "df = df.with_columns(pl.Series(encoded_suburbs, dtype=pl.UInt32).alias(\"suburbs_encoded\"))\n",
    "\n",
    "# Display the first 5 rows after encoding\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f667e7c-ac7a-4ecf-8791-d7faea227ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 17)\n",
      "┌────────────┬─────┬────────┬────────────┬───┬──────────┬────────────┬────────────────┬────────────┐\n",
      "│ Date       ┆ Id  ┆ suburb ┆ postalCode ┆ … ┆ pt_other ┆ pt_terrace ┆ pt_warehouse   ┆ pt_acreage │\n",
      "│ ---        ┆ --- ┆ ---    ┆ ---        ┆   ┆ ---      ┆ ---        ┆ ---            ┆ ---        │\n",
      "│ str        ┆ i64 ┆ str    ┆ i64        ┆   ┆ i32      ┆ i32        ┆ i32            ┆ i32        │\n",
      "╞════════════╪═════╪════════╪════════════╪═══╪══════════╪════════════╪════════════════╪════════════╡\n",
      "│ 2019-06-19 ┆ 1   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "│ 2019-06-13 ┆ 2   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "│ 2019-06-07 ┆ 3   ┆ Whale  ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "│ 2019-05-28 ┆ 4   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "│ 2019-05-22 ┆ 5   ┆ Whale  ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "└────────────┴─────┴────────┴────────────┴───┴──────────┴────────────┴────────────────┴────────────┘\n",
      "\n",
      "Columns after one-hot encoding:\n",
      "['Date', 'Id', 'suburb', 'postalCode', 'sellPrice', 'bed', 'bath', 'car', 'suburbs_encoded', 'pt_house', 'pt_townhouse', 'pt_duplex/semi-detached', 'pt_villa', 'pt_other', 'pt_terrace', 'pt_warehouse', 'pt_acreage']\n",
      "\n",
      "Unique values in 'pt_house' column:\n",
      "shape: (2,)\n",
      "Series: 'pt_house' [i32]\n",
      "[\n",
      "\t0\n",
      "\t1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding for 'propType' using Polars\n",
    "oneshot_encoded = df.with_columns([\n",
    "    pl.when(pl.col('propType') == pt).then(1).otherwise(0).alias(f'pt_{pt}')\n",
    "    for pt in df['propType'].cast(pl.Categorical).unique()\n",
    "])\n",
    "\n",
    "# Drop the original 'propType' column\n",
    "oneshot_encoded = oneshot_encoded.drop('propType')\n",
    "\n",
    "# Display the first 5 rows after one-hot encoding\n",
    "print(oneshot_encoded.head())\n",
    "\n",
    "# Display the list of columns to verify one-hot encoding\n",
    "print(\"\\nColumns after one-hot encoding:\")\n",
    "print(oneshot_encoded.columns)\n",
    "\n",
    "# Check the unique values in one of the new columns\n",
    "pt_columns = [col for col in oneshot_encoded.columns if col.startswith('pt_')]\n",
    "if pt_columns:\n",
    "    first_pt_column = pt_columns[0]\n",
    "    print(f\"\\nUnique values in '{first_pt_column}' column:\")\n",
    "    print(oneshot_encoded[first_pt_column].unique())\n",
    "else:\n",
    "    print(\"\\nNo 'pt_' columns found. One-hot encoding may have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb0ab322-9b22-4c6d-b164-59289c6f7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(oneshot_encoded, on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce5afea-2eb8-4fdc-bbeb-a3069b1ee25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 26)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date</th><th>Id</th><th>suburb</th><th>postalCode</th><th>sellPrice</th><th>bed</th><th>bath</th><th>car</th><th>propType</th><th>suburbs_encoded</th><th>Date_right</th><th>suburb_right</th><th>postalCode_right</th><th>sellPrice_right</th><th>bed_right</th><th>bath_right</th><th>car_right</th><th>suburbs_encoded_right</th><th>pt_house</th><th>pt_townhouse</th><th>pt_duplex/semi-detached</th><th>pt_villa</th><th>pt_other</th><th>pt_terrace</th><th>pt_warehouse</th><th>pt_acreage</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>u32</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>u32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;2019-06-19&quot;</td><td>1</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>1210000</td><td>4.0</td><td>2</td><td>2.0</td><td>&quot;house&quot;</td><td>22</td><td>&quot;2019-06-19&quot;</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>1210000</td><td>4.0</td><td>2</td><td>2.0</td><td>22</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;2019-06-13&quot;</td><td>2</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>2250000</td><td>4.0</td><td>3</td><td>4.0</td><td>&quot;house&quot;</td><td>22</td><td>&quot;2019-06-13&quot;</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>2250000</td><td>4.0</td><td>3</td><td>4.0</td><td>22</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;2019-06-07&quot;</td><td>3</td><td>&quot;Whale Beach&quot;</td><td>2107</td><td>2920000</td><td>3.0</td><td>3</td><td>2.0</td><td>&quot;house&quot;</td><td>654</td><td>&quot;2019-06-07&quot;</td><td>&quot;Whale Beach&quot;</td><td>2107</td><td>2920000</td><td>3.0</td><td>3</td><td>2.0</td><td>654</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;2019-05-28&quot;</td><td>4</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>1530000</td><td>3.0</td><td>1</td><td>2.0</td><td>&quot;house&quot;</td><td>22</td><td>&quot;2019-05-28&quot;</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>1530000</td><td>3.0</td><td>1</td><td>2.0</td><td>22</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;2019-05-22&quot;</td><td>5</td><td>&quot;Whale Beach&quot;</td><td>2107</td><td>8000000</td><td>5.0</td><td>4</td><td>4.0</td><td>&quot;house&quot;</td><td>654</td><td>&quot;2019-05-22&quot;</td><td>&quot;Whale Beach&quot;</td><td>2107</td><td>8000000</td><td>5.0</td><td>4</td><td>4.0</td><td>654</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 26)\n",
       "┌────────────┬─────┬────────┬────────────┬───┬──────────┬────────────┬────────────────┬────────────┐\n",
       "│ Date       ┆ Id  ┆ suburb ┆ postalCode ┆ … ┆ pt_other ┆ pt_terrace ┆ pt_warehouse   ┆ pt_acreage │\n",
       "│ ---        ┆ --- ┆ ---    ┆ ---        ┆   ┆ ---      ┆ ---        ┆ ---            ┆ ---        │\n",
       "│ str        ┆ i64 ┆ str    ┆ i64        ┆   ┆ i32      ┆ i32        ┆ i32            ┆ i32        │\n",
       "╞════════════╪═════╪════════╪════════════╪═══╪══════════╪════════════╪════════════════╪════════════╡\n",
       "│ 2019-06-19 ┆ 1   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "│ 2019-06-13 ┆ 2   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "│ 2019-06-07 ┆ 3   ┆ Whale  ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "│ 2019-05-28 ┆ 4   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "│ 2019-05-22 ┆ 5   ┆ Whale  ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "└────────────┴─────┴────────┴────────────┴───┴──────────┴────────────┴────────────────┴────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029d855-00a0-4fd0-b4f8-a3e3c7537245",
   "metadata": {},
   "source": [
    "## Set Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77afcf3-4d10-4480-b582-52bdcbedcf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 27)\n",
      "┌────────────┬─────┬────────┬────────────┬───┬────────────┬──────────────┬────────────┬─────────┐\n",
      "│ Date       ┆ Id  ┆ suburb ┆ postalCode ┆ … ┆ pt_terrace ┆ pt_warehouse ┆ pt_acreage ┆ TARGET  │\n",
      "│ ---        ┆ --- ┆ ---    ┆ ---        ┆   ┆ ---        ┆ ---          ┆ ---        ┆ ---     │\n",
      "│ str        ┆ i64 ┆ str    ┆ i64        ┆   ┆ i32        ┆ i32          ┆ i32        ┆ i64     │\n",
      "╞════════════╪═════╪════════╪════════════╪═══╪════════════╪══════════════╪════════════╪═════════╡\n",
      "│ 2019-06-19 ┆ 1   ┆ Avalon ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 1210000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "│ 2019-06-13 ┆ 2   ┆ Avalon ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 2250000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "│ 2019-06-07 ┆ 3   ┆ Whale  ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 2920000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "│ 2019-05-28 ┆ 4   ┆ Avalon ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 1530000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "│ 2019-05-22 ┆ 5   ┆ Whale  ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 8000000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "└────────────┴─────┴────────┴────────────┴───┴────────────┴──────────────┴────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'TARGET' that's a copy of 'sellPrice'\n",
    "df = df.with_columns(pl.col('sellPrice').alias('TARGET'))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7af4a128-3b68-4590-88ef-8e314c6857bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Id', 'suburb', 'postalCode', 'sellPrice', 'bed', 'bath', 'car', 'propType', 'suburbs_encoded', 'Date_right', 'suburb_right', 'postalCode_right', 'sellPrice_right', 'bed_right', 'bath_right', 'car_right', 'suburbs_encoded_right', 'pt_house', 'pt_townhouse', 'pt_duplex/semi-detached', 'pt_villa', 'pt_other', 'pt_terrace', 'pt_warehouse', 'pt_acreage', 'TARGET']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3cd9b-0b4e-4bb1-a18f-0fb58c8ccd1a",
   "metadata": {},
   "source": [
    "## Remove Redundant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "222a52ab-636d-46df-b4b0-0791b13627f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 22)\n",
      "┌────────────┬─────┬──────┬─────┬───┬────────────┬──────────────┬────────────┬─────────┐\n",
      "│ postalCode ┆ bed ┆ bath ┆ car ┆ … ┆ pt_terrace ┆ pt_warehouse ┆ pt_acreage ┆ TARGET  │\n",
      "│ ---        ┆ --- ┆ ---  ┆ --- ┆   ┆ ---        ┆ ---          ┆ ---        ┆ ---     │\n",
      "│ i64        ┆ f64 ┆ i64  ┆ f64 ┆   ┆ i32        ┆ i32          ┆ i32        ┆ i64     │\n",
      "╞════════════╪═════╪══════╪═════╪═══╪════════════╪══════════════╪════════════╪═════════╡\n",
      "│ 2107       ┆ 4.0 ┆ 2    ┆ 2.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 1210000 │\n",
      "│ 2107       ┆ 4.0 ┆ 3    ┆ 4.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 2250000 │\n",
      "│ 2107       ┆ 3.0 ┆ 3    ┆ 2.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 2920000 │\n",
      "│ 2107       ┆ 3.0 ┆ 1    ┆ 2.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 1530000 │\n",
      "│ 2107       ┆ 5.0 ┆ 4    ┆ 4.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 8000000 │\n",
      "└────────────┴─────┴──────┴─────┴───┴────────────┴──────────────┴────────────┴─────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4w/6x3yk1r13xvcwchd72ftlnsc0000gn/T/ipykernel_3277/609900798.py:6: DeprecationWarning: named `columns` param is deprecated; use positional `*args` instead.\n",
      "  df_drop = df_drop.drop(columns=columns_to_remove)\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the DataFrame (Polars handles this internally)\n",
    "df_drop = df.clone()\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_remove = [\"Date\", \"Id\", \"suburb\", \"propType\", \"sellPrice\"]\n",
    "df_drop = df_drop.drop(columns=columns_to_remove)\n",
    "\n",
    "# Display the first 5 rows after dropping the columns\n",
    "print(df_drop.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2514117-8297-4b8e-8d3e-3b76120bdb63",
   "metadata": {},
   "source": [
    "## Check null or inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01607878-c1ca-4281-8262-00fa5cc52f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Null:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4w/6x3yk1r13xvcwchd72ftlnsc0000gn/T/ipykernel_3277/469196574.py:4: DeprecationWarning: The `axis` parameter for `DataFrame.sum` is deprecated. Use `DataFrame.sum_horizontal()` to perform horizontal aggregation.\n",
      "  is_null = df.with_columns(pl.all().is_null().any()).sum(axis=1).sum() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for Null values across the DataFrame\n",
    "is_null = df.with_columns(pl.all().is_null().any()).sum(axis=1).sum() > 0\n",
    "print(\"Is Null: \", is_null)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4ff03a7-82df-44b2-946d-c86a81afa129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Null: True\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming 'df' is your existing Polars DataFrame\n",
    "# Check for Null values\n",
    "contains_null = df.select(pl.any_horizontal(pl.all().is_null().any())).item()\n",
    "\n",
    "# Print the result for Null values\n",
    "print(\"Is Null:\", contains_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a3c4255-1228-43ea-9d70-4de4bda0dd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Inf: False\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Check for Infinite values, only applying it to numeric columns\n",
    "#this will error if you try to run on string columns\n",
    "contains_inf = df.select(\n",
    "    pl.any_horizontal(\n",
    "        pl.col(pl.Float64).is_infinite().any()\n",
    "    )\n",
    ").item()\n",
    "\n",
    "# Print the result for Infinite values\n",
    "print(\"Is Inf:\", contains_inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67b90623-504a-4f31-8077-cde8a663befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 27)\n",
      "┌────────────┬─────┬─────────────┬────────────┬───┬────────────┬─────────────┬────────────┬────────┐\n",
      "│ Date       ┆ Id  ┆ suburb      ┆ postalCode ┆ … ┆ pt_terrace ┆ pt_warehous ┆ pt_acreage ┆ TARGET │\n",
      "│ ---        ┆ --- ┆ ---         ┆ ---        ┆   ┆ ---        ┆ e           ┆ ---        ┆ ---    │\n",
      "│ str        ┆ f64 ┆ str         ┆ f64        ┆   ┆ f64        ┆ ---         ┆ f64        ┆ f64    │\n",
      "│            ┆     ┆             ┆            ┆   ┆            ┆ f64         ┆            ┆        │\n",
      "╞════════════╪═════╪═════════════╪════════════╪═══╪════════════╪═════════════╪════════════╪════════╡\n",
      "│ 2019-06-19 ┆ 1.0 ┆ Avalon      ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 1.21e6 │\n",
      "│            ┆     ┆ Beach       ┆            ┆   ┆            ┆             ┆            ┆        │\n",
      "│ 2019-06-13 ┆ 2.0 ┆ Avalon      ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 2.25e6 │\n",
      "│            ┆     ┆ Beach       ┆            ┆   ┆            ┆             ┆            ┆        │\n",
      "│ 2019-06-07 ┆ 3.0 ┆ Whale Beach ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 2.92e6 │\n",
      "│ 2019-05-28 ┆ 4.0 ┆ Avalon      ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 1.53e6 │\n",
      "│            ┆     ┆ Beach       ┆            ┆   ┆            ┆             ┆            ┆        │\n",
      "│ 2019-05-22 ┆ 5.0 ┆ Whale Beach ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 8e6    │\n",
      "└────────────┴─────┴─────────────┴────────────┴───┴────────────┴─────────────┴────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Calculate means for numeric columns\n",
    "numeric_cols = df.select(pl.col(pl.NUMERIC_DTYPES)).columns\n",
    "column_means = df.select([pl.col(col).mean() for col in numeric_cols])\n",
    "\n",
    "# Fill NA values with means for numeric columns\n",
    "df_filled = df.with_columns([\n",
    "    pl.col(col).fill_null(column_means.get_column(col)[0])\n",
    "    for col in numeric_cols\n",
    "])\n",
    "\n",
    "print(df_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d4eac3b-e8cc-4839-9d6e-72e267c563af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Null: False\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming 'df' is your existing Polars DataFrame\n",
    "# Check for Null values\n",
    "contains_null = df_filled.select(pl.any_horizontal(pl.all().is_null().any())).item()\n",
    "\n",
    "# Print the result for Null values\n",
    "print(\"Is Null:\", contains_null)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45026b-015a-438f-aeef-8b9f0c5af5a7",
   "metadata": {},
   "source": [
    "## Remove Redundat Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87f65fc5-4c53-4db7-968b-374bcef53d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Id', 'suburb', 'postalCode', 'sellPrice', 'bed', 'bath', 'car', 'propType', 'suburbs_encoded', 'Date_right', 'suburb_right', 'postalCode_right', 'sellPrice_right', 'bed_right', 'bath_right', 'car_right', 'suburbs_encoded_right', 'pt_house', 'pt_townhouse', 'pt_duplex/semi-detached', 'pt_villa', 'pt_other', 'pt_terrace', 'pt_warehouse', 'pt_acreage', 'TARGET']\n"
     ]
    }
   ],
   "source": [
    "print(df_filled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a59534bf-e41b-4b51-800d-08b09044714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 19)\n",
      "┌────────────┬─────┬──────┬─────┬───┬────────────┬──────────────┬────────────┬────────┐\n",
      "│ postalCode ┆ bed ┆ bath ┆ car ┆ … ┆ pt_terrace ┆ pt_warehouse ┆ pt_acreage ┆ TARGET │\n",
      "│ ---        ┆ --- ┆ ---  ┆ --- ┆   ┆ ---        ┆ ---          ┆ ---        ┆ ---    │\n",
      "│ f64        ┆ f64 ┆ f64  ┆ f64 ┆   ┆ f64        ┆ f64          ┆ f64        ┆ f64    │\n",
      "╞════════════╪═════╪══════╪═════╪═══╪════════════╪══════════════╪════════════╪════════╡\n",
      "│ 2107.0     ┆ 4.0 ┆ 2.0  ┆ 2.0 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 1.21e6 │\n",
      "│ 2107.0     ┆ 4.0 ┆ 3.0  ┆ 4.0 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 2.25e6 │\n",
      "│ 2107.0     ┆ 3.0 ┆ 3.0  ┆ 2.0 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 2.92e6 │\n",
      "│ 2107.0     ┆ 3.0 ┆ 1.0  ┆ 2.0 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 1.53e6 │\n",
      "│ 2107.0     ┆ 5.0 ┆ 4.0  ┆ 4.0 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 8e6    │\n",
      "└────────────┴─────┴──────┴─────┴───┴────────────┴──────────────┴────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Remove features\n",
    "df_drop = df_filled.drop([\"Date\",\"Date_right\", \"Id\", \"suburb\", \"suburb_right\", \"propType\", \"sellPrice_right\", \"sellPrice\"])\n",
    "\n",
    "print(df_drop.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3dfd1f0-fc9a-4d43-a298-363abf03efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['postalCode', 'bed', 'bath', 'car', 'suburbs_encoded', 'postalCode_right', 'bed_right', 'bath_right', 'car_right', 'suburbs_encoded_right', 'pt_house', 'pt_townhouse', 'pt_duplex/semi-detached', 'pt_villa', 'pt_other', 'pt_terrace', 'pt_warehouse', 'pt_acreage', 'TARGET']\n"
     ]
    }
   ],
   "source": [
    "print(df_drop.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d39285-4b4d-4b0c-8821-bbef5837d1f5",
   "metadata": {},
   "source": [
    "## Feature Scaling - Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c7c58ca-b7a5-43a8-844c-26a200d0fa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 19)\n",
      "┌────────────┬──────────┬──────────┬───────┬───┬────────────┬──────────────┬────────────┬────────┐\n",
      "│ postalCode ┆ bed      ┆ bath     ┆ car   ┆ … ┆ pt_terrace ┆ pt_warehouse ┆ pt_acreage ┆ TARGET │\n",
      "│ ---        ┆ ---      ┆ ---      ┆ ---   ┆   ┆ ---        ┆ ---          ┆ ---        ┆ ---    │\n",
      "│ f64        ┆ f64      ┆ f64      ┆ f64   ┆   ┆ f64        ┆ f64          ┆ f64        ┆ f64    │\n",
      "╞════════════╪══════════╪══════════╪═══════╪═══╪════════════╪══════════════╪════════════╪════════╡\n",
      "│ 0.037179   ┆ 0.030612 ┆ 0.010204 ┆ 0.025 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 1.21e6 │\n",
      "│ 0.037179   ┆ 0.030612 ┆ 0.020408 ┆ 0.075 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 2.25e6 │\n",
      "│ 0.037179   ┆ 0.020408 ┆ 0.020408 ┆ 0.025 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 2.92e6 │\n",
      "│ 0.037179   ┆ 0.020408 ┆ 0.0      ┆ 0.025 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 1.53e6 │\n",
      "│ 0.037179   ┆ 0.040816 ┆ 0.030612 ┆ 0.075 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 8e6    │\n",
      "└────────────┴──────────┴──────────┴───────┴───┴────────────┴──────────────┴────────────┴────────┘\n",
      "[Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming df_drop is your Polars DataFrame after dropping unnecessary columns\n",
    "df_scaling = df_drop.clone()  # Create a copy of df_drop\n",
    "\n",
    "# Function to check if a column is numeric\n",
    "def is_numeric(col):\n",
    "    return col.dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64, pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64, pl.Float32, pl.Float64]\n",
    "\n",
    "# Convert date columns to timestamps, other string columns to categorical\n",
    "for col in df_scaling.columns:\n",
    "    if df_scaling[col].dtype == pl.Utf8:\n",
    "        if \"Date\" in col:  # Assuming date columns have \"Date\" in their name\n",
    "            df_scaling = df_scaling.with_columns(pl.col(col).str.to_date().cast(pl.Int64).alias(col))\n",
    "        else:\n",
    "            df_scaling = df_scaling.with_columns(pl.col(col).cast(pl.Categorical).cast(pl.Int32).alias(col))\n",
    "\n",
    "# Apply min-max scaling to all numeric columns except TARGET\n",
    "columns_to_scale = [col for col in df_scaling.columns if col != \"TARGET\" and is_numeric(df_scaling[col])]\n",
    "\n",
    "df_scaling = df_scaling.with_columns([\n",
    "    ((pl.col(col) - pl.col(col).min()) / (pl.col(col).max() - pl.col(col).min())).alias(col)\n",
    "    for col in columns_to_scale\n",
    "])\n",
    "\n",
    "print(df_scaling.head())\n",
    "print(df_scaling.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eddbfa3-ca1b-465f-84a8-20b20c3f9bf1",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02a60d3d-3005-40ac-93bc-c8865aec469b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>postalCode</th><th>bed</th><th>bath</th><th>car</th><th>suburbs_encoded</th><th>postalCode_right</th><th>bed_right</th><th>bath_right</th><th>car_right</th><th>suburbs_encoded_right</th><th>pt_house</th><th>pt_townhouse</th><th>pt_duplex/semi-detached</th><th>pt_villa</th><th>pt_other</th><th>pt_terrace</th><th>pt_warehouse</th><th>pt_acreage</th><th>TARGET</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2107.0</td><td>4.0</td><td>2.0</td><td>2.0</td><td>22.0</td><td>2107.0</td><td>4.0</td><td>2.0</td><td>2.0</td><td>22.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.21e6</td></tr><tr><td>2107.0</td><td>4.0</td><td>3.0</td><td>4.0</td><td>22.0</td><td>2107.0</td><td>4.0</td><td>3.0</td><td>4.0</td><td>22.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.25e6</td></tr><tr><td>2107.0</td><td>3.0</td><td>3.0</td><td>2.0</td><td>654.0</td><td>2107.0</td><td>3.0</td><td>3.0</td><td>2.0</td><td>654.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.92e6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 19)\n",
       "┌────────────┬─────┬──────┬─────┬───┬────────────┬──────────────┬────────────┬────────┐\n",
       "│ postalCode ┆ bed ┆ bath ┆ car ┆ … ┆ pt_terrace ┆ pt_warehouse ┆ pt_acreage ┆ TARGET │\n",
       "│ ---        ┆ --- ┆ ---  ┆ --- ┆   ┆ ---        ┆ ---          ┆ ---        ┆ ---    │\n",
       "│ f64        ┆ f64 ┆ f64  ┆ f64 ┆   ┆ f64        ┆ f64          ┆ f64        ┆ f64    │\n",
       "╞════════════╪═════╪══════╪═════╪═══╪════════════╪══════════════╪════════════╪════════╡\n",
       "│ 2107.0     ┆ 4.0 ┆ 2.0  ┆ 2.0 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 1.21e6 │\n",
       "│ 2107.0     ┆ 4.0 ┆ 3.0  ┆ 4.0 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 2.25e6 │\n",
       "│ 2107.0     ┆ 3.0 ┆ 3.0  ┆ 2.0 ┆ … ┆ 0.0        ┆ 0.0          ┆ 0.0        ┆ 2.92e6 │\n",
       "└────────────┴─────┴──────┴─────┴───┴────────────┴──────────────┴────────────┴────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use correct Dataframe\n",
    "is_deep_learning = False\n",
    "df_tts = df_scaling.clone() if is_deep_learning else df_drop.clone()\n",
    "df_tts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8a83985-e5a7-414a-8ba5-d1b1110a8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Values: \n",
      " [[2.107e+03 4.000e+00 2.000e+00 2.000e+00 2.200e+01 2.107e+03 4.000e+00\n",
      "  2.000e+00 2.000e+00 2.200e+01 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [2.107e+03 4.000e+00 3.000e+00 4.000e+00 2.200e+01 2.107e+03 4.000e+00\n",
      "  3.000e+00 4.000e+00 2.200e+01 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00]]\n",
      "y Values: \n",
      " [1210000. 2250000. 2920000. 1530000. 8000000.]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming df_tts is already defined as a Polars DataFrame\n",
    "\n",
    "# Split X and y data\n",
    "# X will contain all columns except the last one\n",
    "X = df_tts[:, :-1].to_numpy()\n",
    "\n",
    "# y will contain only the last column\n",
    "y = df_tts[:, -1].to_numpy()\n",
    "\n",
    "# Print the first 2 rows of X\n",
    "print(\"X Values: \\n\", X[:2])\n",
    "\n",
    "# Print the first 5 rows of y\n",
    "print(\"y Values: \\n\", y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28fed583-5c99-4fad-ab23-3e58208e5ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (179553, 18)\n",
      "X_test shape:  (19951, 18)\n",
      "y_train shape:  (179553,)\n",
      "y_test shape:  (19951,)\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split\n",
    "# x_train and y_train are the training datasets\n",
    "# X_test and y_test are the testing datasets\n",
    "# test_size=0.1 means 10% of the data will be used for testing\n",
    "# random_state=1 ensures reproducibility of the split\n",
    "# shuffle=True ensures the data is shuffled before splitting; you can decide if you want recent data or not\n",
    "x_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1, shuffle=True)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acbab61-9984-40e5-b27b-2321a5a9f379",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ea2fdcd-6a9d-4e09-997e-267b438f4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor # a random forest regressor\n",
    "\n",
    "# Train Regressor\n",
    "# Initializing the RandomForestRegressor with the following parameters:\n",
    "# n_estimators=100: The number of trees in the forest.\n",
    "# max_depth=10: The maximum depth of each tree.\n",
    "# random_state=0: Ensures reproducibility of the results by setting the seed.\n",
    "regressor = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=0)\n",
    "\n",
    "# Now, you can fit the regressor to your training data\n",
    "# regressor.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4ceef50-ac40-42a0-922e-beb47cbd3546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_compute_oob_predictions',\n",
       " '_compute_partial_dependence_recursion',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_estimator_type',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_estimators_indices',\n",
       " '_get_metadata_request',\n",
       " '_get_oob_predictions',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_make_estimator',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_set_oob_score_and_attributes',\n",
       " '_validate_X_predict',\n",
       " '_validate_data',\n",
       " '_validate_estimator',\n",
       " '_validate_params',\n",
       " '_validate_y_class_weight',\n",
       " 'apply',\n",
       " 'decision_path',\n",
       " 'estimators_samples_',\n",
       " 'feature_importances_',\n",
       " 'fit',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'predict',\n",
       " 'score',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_score_request']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de4d5ca7-b310-4da3-9a83-abdb9e5801fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=10, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, you can fit the regressor to your training data\n",
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2277d692-664f-4a60-b04a-98da056f0f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Predictions  [593681.0, 2022675.0, 1112679.0, 1045638.0, 869990.0]\n",
      "Test Actuals  [ 730000. 1350100.  860000. 1390000.  985000.]\n"
     ]
    }
   ],
   "source": [
    "# make Predictions on Test Set\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred = [round(x, 0) for x in y_pred] # doing a for loop in a list\n",
    "print(\"Test Predictions \", y_pred[:5]) # gets the first 5\n",
    "print(\"Test Actuals \", y_test[:5]) # gets the first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "598cf281-3bea-4751-9481-efa7b38f2cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [-399498.62273728 -372750.85835856 -405046.15401898 -390448.23879278\n",
      " -378576.3210264  -373998.60345864 -406443.36539599 -357545.94796804\n",
      " -416258.29409479 -386629.6352343  -367704.32557829 -379682.49451279\n",
      " -363764.21540351 -417977.97095531 -421167.94399914]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "\n",
    "# Check Accuracy\n",
    "# Define the cross-validation strategy\n",
    "# n_splits=5: Number of folds in each round of cross-validation\n",
    "# n_repeats=3: Number of times the cross-validation is repeated\n",
    "# random_state=1: Seed for reproducibility\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "# Perform cross-validation\n",
    "# regressor: The model to evaluate\n",
    "# x_train, y_train: The training data\n",
    "# scoring=\"neg_mean_absolute_error\": Evaluation metric (negative mean absolute error)\n",
    "# cv=cv: Cross-validation strategy defined above\n",
    "# n_jobs=-1: Use all available processors for computation\n",
    "# error_score=\"raise\": Raise an error if one occurs\n",
    "n_scores = cross_val_score(regressor, x_train, y_train, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1, error_score=\"raise\")\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", n_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c3f46d1-1edd-4b8e-bc51-54b98cb2e891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Avg:  389166.1994356542\n",
      "MAE Std:  20101.47639828163\n"
     ]
    }
   ],
   "source": [
    "# Reoport Performance\n",
    "print(\"MAE Avg: \", abs(n_scores.mean()))\n",
    "print(\"MAE Std: \", n_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79adcf-07c3-4a8f-9d48-5b311665c1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
