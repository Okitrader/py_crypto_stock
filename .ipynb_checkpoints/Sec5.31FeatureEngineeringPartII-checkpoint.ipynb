{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f5abd8-921a-4e3e-aa80-37ee6c204726",
   "metadata": {},
   "source": [
    "# Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a837c4a-ec38-49e7-8984-6161913d7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Management\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from pandas_datareader.data import DataReader\n",
    "from ta import add_all_ta_features\n",
    "\n",
    "#Statistics\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "#Data Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "# Supervised Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Reporting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767552d-8a2c-4c44-987d-8639324af379",
   "metadata": {},
   "source": [
    "# Data Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35172e61-ef5c-4463-811c-8d7a48c8a7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Data: 199504\n",
      "shape: (5, 9)\n",
      "┌────────────┬─────┬──────────────┬────────────┬───┬─────┬──────┬─────┬──────────┐\n",
      "│ Date       ┆ Id  ┆ suburb       ┆ postalCode ┆ … ┆ bed ┆ bath ┆ car ┆ propType │\n",
      "│ ---        ┆ --- ┆ ---          ┆ ---        ┆   ┆ --- ┆ ---  ┆ --- ┆ ---      │\n",
      "│ str        ┆ i64 ┆ str          ┆ i64        ┆   ┆ f64 ┆ i64  ┆ f64 ┆ str      │\n",
      "╞════════════╪═════╪══════════════╪════════════╪═══╪═════╪══════╪═════╪══════════╡\n",
      "│ 2019-06-19 ┆ 1   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 4.0 ┆ 2    ┆ 2.0 ┆ house    │\n",
      "│ 2019-06-13 ┆ 2   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 4.0 ┆ 3    ┆ 4.0 ┆ house    │\n",
      "│ 2019-06-07 ┆ 3   ┆ Whale Beach  ┆ 2107       ┆ … ┆ 3.0 ┆ 3    ┆ 2.0 ┆ house    │\n",
      "│ 2019-05-28 ┆ 4   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 3.0 ┆ 1    ┆ 2.0 ┆ house    │\n",
      "│ 2019-05-22 ┆ 5   ┆ Whale Beach  ┆ 2107       ┆ … ┆ 5.0 ┆ 4    ┆ 4.0 ┆ house    │\n",
      "└────────────┴─────┴──────────────┴────────────┴───┴─────┴──────┴─────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Set the file path\n",
    "file_path = \"/Users/okitrader/OneDrive/py_crypto_stock/SydneyHousePrices.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "df = pl.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(f'Length of Data: {len(df)}')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05bccfed-cdc6-4473-a1cc-3597649efddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Id', 'suburb', 'postalCode', 'sellPrice', 'bed', 'bath', 'car', 'propType']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b229bd14-d5a8-4e51-b5df-43562e482a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "OrderedDict({'Date': String, 'Id': Int64, 'suburb': String, 'postalCode': Int64, 'sellPrice': Int64, 'bed': Float64, 'bath': Int64, 'car': Float64, 'propType': String})\n",
      "\n",
      "Number of rows: 199504\n",
      "Number of columns: 9\n",
      "\n",
      "Null counts for each column:\n",
      "shape: (1, 9)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ Date_null ┆ Id_null_c ┆ suburb_nu ┆ postalCod ┆ … ┆ bed_null_ ┆ bath_null ┆ car_null_ ┆ propType │\n",
      "│ _count    ┆ ount      ┆ ll_count  ┆ e_null_co ┆   ┆ count     ┆ _count    ┆ count     ┆ _null_co │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ unt       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ unt      │\n",
      "│ u32       ┆ u32       ┆ u32       ┆ ---       ┆   ┆ u32       ┆ u32       ┆ u32       ┆ ---      │\n",
      "│           ┆           ┆           ┆ u32       ┆   ┆           ┆           ┆           ┆ u32      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 0         ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 154       ┆ 0         ┆ 18151     ┆ 0        │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame schema\n",
    "print(\"Schema:\")\n",
    "print(df.schema)\n",
    "\n",
    "# Display number of rows and columns\n",
    "print(\"\\nNumber of rows:\", df.height)\n",
    "print(\"Number of columns:\", df.width)\n",
    "\n",
    "# Display null counts for each column\n",
    "print(\"\\nNull counts for each column:\")\n",
    "null_counts = df.select([pl.col(col).is_null().sum().alias(f\"{col}_null_count\") for col in df.columns])\n",
    "print(null_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc7df1-598d-4dfb-babc-10f74a3d4219",
   "metadata": {},
   "source": [
    "# Feature Engineering - Common Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bf2bb-31d9-47be-a0a0-19f2f131b1ad",
   "metadata": {},
   "source": [
    "## Handle Non-Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95ee72a-0333-477a-85e5-07af74893c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Suburbs:  685\n",
      "Preform label encoding\n"
     ]
    }
   ],
   "source": [
    "# Count unique items for 'suburb'\n",
    "suburb_text_unique = df['suburb'].unique()\n",
    "suburb_text_unique_list = suburb_text_unique.to_list() # prints the full list for viewing\n",
    "print('Unique Suburbs: ', len(suburb_text_unique))\n",
    "print('Preform label encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06dde192-8fbe-4890-b4d5-cf4c247b659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Prop Types:  8\n",
      "Preform OneHotEncoding encoding\n"
     ]
    }
   ],
   "source": [
    "# Count unique items for propType\n",
    "prop_type_text_unique = df['propType'].unique()\n",
    "print('Unique Prop Types: ', len(prop_type_text_unique))\n",
    "print('Preform OneHotEncoding encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1603cb80-5331-48c6-bdd7-3301b5f243c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 10)\n",
      "┌────────────┬─────┬──────────────┬────────────┬───┬──────┬─────┬──────────┬─────────────────┐\n",
      "│ Date       ┆ Id  ┆ suburb       ┆ postalCode ┆ … ┆ bath ┆ car ┆ propType ┆ suburbs_encoded │\n",
      "│ ---        ┆ --- ┆ ---          ┆ ---        ┆   ┆ ---  ┆ --- ┆ ---      ┆ ---             │\n",
      "│ str        ┆ i64 ┆ str          ┆ i64        ┆   ┆ i64  ┆ f64 ┆ str      ┆ u32             │\n",
      "╞════════════╪═════╪══════════════╪════════════╪═══╪══════╪═════╪══════════╪═════════════════╡\n",
      "│ 2019-06-19 ┆ 1   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 2    ┆ 2.0 ┆ house    ┆ 22              │\n",
      "│ 2019-06-13 ┆ 2   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 3    ┆ 4.0 ┆ house    ┆ 22              │\n",
      "│ 2019-06-07 ┆ 3   ┆ Whale Beach  ┆ 2107       ┆ … ┆ 3    ┆ 2.0 ┆ house    ┆ 654             │\n",
      "│ 2019-05-28 ┆ 4   ┆ Avalon Beach ┆ 2107       ┆ … ┆ 1    ┆ 2.0 ┆ house    ┆ 22              │\n",
      "│ 2019-05-22 ┆ 5   ┆ Whale Beach  ┆ 2107       ┆ … ┆ 4    ┆ 4.0 ┆ house    ┆ 654             │\n",
      "└────────────┴─────┴──────────────┴────────────┴───┴──────┴─────┴──────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding for 'suburb'\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Perform label encoding on the 'suburb' column to convert categorical text data into numerical values\n",
    "# The LabelEncoder's fit_transform method fits the encoder and returns the transformed values as a NumPy array\n",
    "# This step is necessary for machine learning models which require numerical input data\n",
    "encoded_suburbs = labelencoder.fit_transform(df['suburb'].to_numpy())\n",
    "\n",
    "\n",
    "# Add the encoded column to the DataFrame\n",
    "df = df.with_columns(pl.Series(encoded_suburbs, dtype=pl.UInt32).alias(\"suburbs_encoded\"))\n",
    "\n",
    "# Display the first 5 rows after encoding\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f667e7c-ac7a-4ecf-8791-d7faea227ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 17)\n",
      "┌────────────┬─────┬────────┬────────────┬───┬──────────┬────────────┬────────────────┬────────────┐\n",
      "│ Date       ┆ Id  ┆ suburb ┆ postalCode ┆ … ┆ pt_other ┆ pt_terrace ┆ pt_warehouse   ┆ pt_acreage │\n",
      "│ ---        ┆ --- ┆ ---    ┆ ---        ┆   ┆ ---      ┆ ---        ┆ ---            ┆ ---        │\n",
      "│ str        ┆ i64 ┆ str    ┆ i64        ┆   ┆ i32      ┆ i32        ┆ i32            ┆ i32        │\n",
      "╞════════════╪═════╪════════╪════════════╪═══╪══════════╪════════════╪════════════════╪════════════╡\n",
      "│ 2019-06-19 ┆ 1   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "│ 2019-06-13 ┆ 2   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "│ 2019-06-07 ┆ 3   ┆ Whale  ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "│ 2019-05-28 ┆ 4   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "│ 2019-05-22 ┆ 5   ┆ Whale  ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
      "└────────────┴─────┴────────┴────────────┴───┴──────────┴────────────┴────────────────┴────────────┘\n",
      "\n",
      "Columns after one-hot encoding:\n",
      "['Date', 'Id', 'suburb', 'postalCode', 'sellPrice', 'bed', 'bath', 'car', 'suburbs_encoded', 'pt_house', 'pt_townhouse', 'pt_duplex/semi-detached', 'pt_villa', 'pt_other', 'pt_terrace', 'pt_warehouse', 'pt_acreage']\n",
      "\n",
      "Unique values in 'pt_house' column:\n",
      "shape: (2,)\n",
      "Series: 'pt_house' [i32]\n",
      "[\n",
      "\t0\n",
      "\t1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding for 'propType' using Polars\n",
    "oneshot_encoded = df.with_columns([\n",
    "    pl.when(pl.col('propType') == pt).then(1).otherwise(0).alias(f'pt_{pt}')\n",
    "    for pt in df['propType'].cast(pl.Categorical).unique()\n",
    "])\n",
    "\n",
    "# Drop the original 'propType' column\n",
    "oneshot_encoded = oneshot_encoded.drop('propType')\n",
    "\n",
    "# Display the first 5 rows after one-hot encoding\n",
    "print(oneshot_encoded.head())\n",
    "\n",
    "# Display the list of columns to verify one-hot encoding\n",
    "print(\"\\nColumns after one-hot encoding:\")\n",
    "print(oneshot_encoded.columns)\n",
    "\n",
    "# Check the unique values in one of the new columns\n",
    "pt_columns = [col for col in oneshot_encoded.columns if col.startswith('pt_')]\n",
    "if pt_columns:\n",
    "    first_pt_column = pt_columns[0]\n",
    "    print(f\"\\nUnique values in '{first_pt_column}' column:\")\n",
    "    print(oneshot_encoded[first_pt_column].unique())\n",
    "else:\n",
    "    print(\"\\nNo 'pt_' columns found. One-hot encoding may have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb0ab322-9b22-4c6d-b164-59289c6f7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(oneshot_encoded, on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ce5afea-2eb8-4fdc-bbeb-a3069b1ee25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 26)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date</th><th>Id</th><th>suburb</th><th>postalCode</th><th>sellPrice</th><th>bed</th><th>bath</th><th>car</th><th>propType</th><th>suburbs_encoded</th><th>Date_right</th><th>suburb_right</th><th>postalCode_right</th><th>sellPrice_right</th><th>bed_right</th><th>bath_right</th><th>car_right</th><th>suburbs_encoded_right</th><th>pt_house</th><th>pt_townhouse</th><th>pt_duplex/semi-detached</th><th>pt_villa</th><th>pt_other</th><th>pt_terrace</th><th>pt_warehouse</th><th>pt_acreage</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>u32</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>u32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;2019-06-19&quot;</td><td>1</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>1210000</td><td>4.0</td><td>2</td><td>2.0</td><td>&quot;house&quot;</td><td>22</td><td>&quot;2019-06-19&quot;</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>1210000</td><td>4.0</td><td>2</td><td>2.0</td><td>22</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;2019-06-13&quot;</td><td>2</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>2250000</td><td>4.0</td><td>3</td><td>4.0</td><td>&quot;house&quot;</td><td>22</td><td>&quot;2019-06-13&quot;</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>2250000</td><td>4.0</td><td>3</td><td>4.0</td><td>22</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;2019-06-07&quot;</td><td>3</td><td>&quot;Whale Beach&quot;</td><td>2107</td><td>2920000</td><td>3.0</td><td>3</td><td>2.0</td><td>&quot;house&quot;</td><td>654</td><td>&quot;2019-06-07&quot;</td><td>&quot;Whale Beach&quot;</td><td>2107</td><td>2920000</td><td>3.0</td><td>3</td><td>2.0</td><td>654</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;2019-05-28&quot;</td><td>4</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>1530000</td><td>3.0</td><td>1</td><td>2.0</td><td>&quot;house&quot;</td><td>22</td><td>&quot;2019-05-28&quot;</td><td>&quot;Avalon Beach&quot;</td><td>2107</td><td>1530000</td><td>3.0</td><td>1</td><td>2.0</td><td>22</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;2019-05-22&quot;</td><td>5</td><td>&quot;Whale Beach&quot;</td><td>2107</td><td>8000000</td><td>5.0</td><td>4</td><td>4.0</td><td>&quot;house&quot;</td><td>654</td><td>&quot;2019-05-22&quot;</td><td>&quot;Whale Beach&quot;</td><td>2107</td><td>8000000</td><td>5.0</td><td>4</td><td>4.0</td><td>654</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 26)\n",
       "┌────────────┬─────┬────────┬────────────┬───┬──────────┬────────────┬────────────────┬────────────┐\n",
       "│ Date       ┆ Id  ┆ suburb ┆ postalCode ┆ … ┆ pt_other ┆ pt_terrace ┆ pt_warehouse   ┆ pt_acreage │\n",
       "│ ---        ┆ --- ┆ ---    ┆ ---        ┆   ┆ ---      ┆ ---        ┆ ---            ┆ ---        │\n",
       "│ str        ┆ i64 ┆ str    ┆ i64        ┆   ┆ i32      ┆ i32        ┆ i32            ┆ i32        │\n",
       "╞════════════╪═════╪════════╪════════════╪═══╪══════════╪════════════╪════════════════╪════════════╡\n",
       "│ 2019-06-19 ┆ 1   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "│ 2019-06-13 ┆ 2   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "│ 2019-06-07 ┆ 3   ┆ Whale  ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "│ 2019-05-28 ┆ 4   ┆ Avalon ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "│ 2019-05-22 ┆ 5   ┆ Whale  ┆ 2107       ┆ … ┆ 0        ┆ 0          ┆ 0              ┆ 0          │\n",
       "│            ┆     ┆ Beach  ┆            ┆   ┆          ┆            ┆                ┆            │\n",
       "└────────────┴─────┴────────┴────────────┴───┴──────────┴────────────┴────────────────┴────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029d855-00a0-4fd0-b4f8-a3e3c7537245",
   "metadata": {},
   "source": [
    "## Set Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a77afcf3-4d10-4480-b582-52bdcbedcf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 27)\n",
      "┌────────────┬─────┬────────┬────────────┬───┬────────────┬──────────────┬────────────┬─────────┐\n",
      "│ Date       ┆ Id  ┆ suburb ┆ postalCode ┆ … ┆ pt_terrace ┆ pt_warehouse ┆ pt_acreage ┆ TARGET  │\n",
      "│ ---        ┆ --- ┆ ---    ┆ ---        ┆   ┆ ---        ┆ ---          ┆ ---        ┆ ---     │\n",
      "│ str        ┆ i64 ┆ str    ┆ i64        ┆   ┆ i32        ┆ i32          ┆ i32        ┆ i64     │\n",
      "╞════════════╪═════╪════════╪════════════╪═══╪════════════╪══════════════╪════════════╪═════════╡\n",
      "│ 2019-06-19 ┆ 1   ┆ Avalon ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 1210000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "│ 2019-06-13 ┆ 2   ┆ Avalon ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 2250000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "│ 2019-06-07 ┆ 3   ┆ Whale  ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 2920000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "│ 2019-05-28 ┆ 4   ┆ Avalon ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 1530000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "│ 2019-05-22 ┆ 5   ┆ Whale  ┆ 2107       ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 8000000 │\n",
      "│            ┆     ┆ Beach  ┆            ┆   ┆            ┆              ┆            ┆         │\n",
      "└────────────┴─────┴────────┴────────────┴───┴────────────┴──────────────┴────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'TARGET' that's a copy of 'sellPrice'\n",
    "df = df.with_columns(pl.col('sellPrice').alias('TARGET'))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7af4a128-3b68-4590-88ef-8e314c6857bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Id', 'suburb', 'postalCode', 'sellPrice', 'bed', 'bath', 'car', 'propType', 'suburbs_encoded', 'Date_right', 'suburb_right', 'postalCode_right', 'sellPrice_right', 'bed_right', 'bath_right', 'car_right', 'suburbs_encoded_right', 'pt_house', 'pt_townhouse', 'pt_duplex/semi-detached', 'pt_villa', 'pt_other', 'pt_terrace', 'pt_warehouse', 'pt_acreage', 'TARGET']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3cd9b-0b4e-4bb1-a18f-0fb58c8ccd1a",
   "metadata": {},
   "source": [
    "## Remove Redundant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "222a52ab-636d-46df-b4b0-0791b13627f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 22)\n",
      "┌────────────┬─────┬──────┬─────┬───┬────────────┬──────────────┬────────────┬─────────┐\n",
      "│ postalCode ┆ bed ┆ bath ┆ car ┆ … ┆ pt_terrace ┆ pt_warehouse ┆ pt_acreage ┆ TARGET  │\n",
      "│ ---        ┆ --- ┆ ---  ┆ --- ┆   ┆ ---        ┆ ---          ┆ ---        ┆ ---     │\n",
      "│ i64        ┆ f64 ┆ i64  ┆ f64 ┆   ┆ i32        ┆ i32          ┆ i32        ┆ i64     │\n",
      "╞════════════╪═════╪══════╪═════╪═══╪════════════╪══════════════╪════════════╪═════════╡\n",
      "│ 2107       ┆ 4.0 ┆ 2    ┆ 2.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 1210000 │\n",
      "│ 2107       ┆ 4.0 ┆ 3    ┆ 4.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 2250000 │\n",
      "│ 2107       ┆ 3.0 ┆ 3    ┆ 2.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 2920000 │\n",
      "│ 2107       ┆ 3.0 ┆ 1    ┆ 2.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 1530000 │\n",
      "│ 2107       ┆ 5.0 ┆ 4    ┆ 4.0 ┆ … ┆ 0          ┆ 0            ┆ 0          ┆ 8000000 │\n",
      "└────────────┴─────┴──────┴─────┴───┴────────────┴──────────────┴────────────┴─────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4w/6x3yk1r13xvcwchd72ftlnsc0000gn/T/ipykernel_38780/609900798.py:6: DeprecationWarning: named `columns` param is deprecated; use positional `*args` instead.\n",
      "  df_drop = df_drop.drop(columns=columns_to_remove)\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the DataFrame (Polars handles this internally)\n",
    "df_drop = df.clone()\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_remove = [\"Date\", \"Id\", \"suburb\", \"propType\", \"sellPrice\"]\n",
    "df_drop = df_drop.drop(columns=columns_to_remove)\n",
    "\n",
    "# Display the first 5 rows after dropping the columns\n",
    "print(df_drop.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2514117-8297-4b8e-8d3e-3b76120bdb63",
   "metadata": {},
   "source": [
    "## Check null or inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01607878-c1ca-4281-8262-00fa5cc52f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Null:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4w/6x3yk1r13xvcwchd72ftlnsc0000gn/T/ipykernel_38780/469196574.py:4: DeprecationWarning: The `axis` parameter for `DataFrame.sum` is deprecated. Use `DataFrame.sum_horizontal()` to perform horizontal aggregation.\n",
      "  is_null = df.with_columns(pl.all().is_null().any()).sum(axis=1).sum() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for Null values across the DataFrame\n",
    "is_null = df.with_columns(pl.all().is_null().any()).sum(axis=1).sum() > 0\n",
    "print(\"Is Null: \", is_null)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4ff03a7-82df-44b2-946d-c86a81afa129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Null: True\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming 'df' is your existing Polars DataFrame\n",
    "# Check for Null values\n",
    "contains_null = df.select(pl.any_horizontal(pl.all().is_null().any())).item()\n",
    "\n",
    "# Print the result for Null values\n",
    "print(\"Is Null:\", contains_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a3c4255-1228-43ea-9d70-4de4bda0dd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Inf: False\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Check for Infinite values, only applying it to numeric columns\n",
    "#this will error if you try to run on string columns\n",
    "contains_inf = df.select(\n",
    "    pl.any_horizontal(\n",
    "        pl.col(pl.Float64).is_infinite().any()\n",
    "    )\n",
    ").item()\n",
    "\n",
    "# Print the result for Infinite values\n",
    "print(\"Is Inf:\", contains_inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67b90623-504a-4f31-8077-cde8a663befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 27)\n",
      "┌────────────┬─────┬─────────────┬────────────┬───┬────────────┬─────────────┬────────────┬────────┐\n",
      "│ Date       ┆ Id  ┆ suburb      ┆ postalCode ┆ … ┆ pt_terrace ┆ pt_warehous ┆ pt_acreage ┆ TARGET │\n",
      "│ ---        ┆ --- ┆ ---         ┆ ---        ┆   ┆ ---        ┆ e           ┆ ---        ┆ ---    │\n",
      "│ str        ┆ f64 ┆ str         ┆ f64        ┆   ┆ f64        ┆ ---         ┆ f64        ┆ f64    │\n",
      "│            ┆     ┆             ┆            ┆   ┆            ┆ f64         ┆            ┆        │\n",
      "╞════════════╪═════╪═════════════╪════════════╪═══╪════════════╪═════════════╪════════════╪════════╡\n",
      "│ 2019-06-19 ┆ 1.0 ┆ Avalon      ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 1.21e6 │\n",
      "│            ┆     ┆ Beach       ┆            ┆   ┆            ┆             ┆            ┆        │\n",
      "│ 2019-06-13 ┆ 2.0 ┆ Avalon      ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 2.25e6 │\n",
      "│            ┆     ┆ Beach       ┆            ┆   ┆            ┆             ┆            ┆        │\n",
      "│ 2019-06-07 ┆ 3.0 ┆ Whale Beach ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 2.92e6 │\n",
      "│ 2019-05-28 ┆ 4.0 ┆ Avalon      ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 1.53e6 │\n",
      "│            ┆     ┆ Beach       ┆            ┆   ┆            ┆             ┆            ┆        │\n",
      "│ 2019-05-22 ┆ 5.0 ┆ Whale Beach ┆ 2107.0     ┆ … ┆ 0.0        ┆ 0.0         ┆ 0.0        ┆ 8e6    │\n",
      "└────────────┴─────┴─────────────┴────────────┴───┴────────────┴─────────────┴────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Calculate means for numeric columns\n",
    "numeric_cols = df.select(pl.col(pl.NUMERIC_DTYPES)).columns\n",
    "column_means = df.select([pl.col(col).mean() for col in numeric_cols])\n",
    "\n",
    "# Fill NA values with means for numeric columns\n",
    "df_filled = df.with_columns([\n",
    "    pl.col(col).fill_null(column_means.get_column(col)[0])\n",
    "    for col in numeric_cols\n",
    "])\n",
    "\n",
    "print(df_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d4eac3b-e8cc-4839-9d6e-72e267c563af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Null: False\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming 'df' is your existing Polars DataFrame\n",
    "# Check for Null values\n",
    "contains_null = df_filled.select(pl.any_horizontal(pl.all().is_null().any())).item()\n",
    "\n",
    "# Print the result for Null values\n",
    "print(\"Is Null:\", contains_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5409b-83c0-42f4-a12e-8589e5587126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
