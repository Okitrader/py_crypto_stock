{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38acac95-d742-44fa-ae5b-71fc7d28b886",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fca65-aea9-4f1c-ac23-839141123d8f",
   "metadata": {},
   "source": [
    "# Deep Learning with Sequential Data: LSTM Networks\n",
    "\n",
    "## Key Points:\n",
    "\n",
    "1. **Purpose**: Demonstrating how to use sequential data in neural networks, specifically with Long Short-Term Memory (LSTM) networks.\n",
    "\n",
    "2. **Data Preparation**:\n",
    "   - Using S&P 500 data with hidden Markov model features\n",
    "   - Adding rolling returns and a target for regression\n",
    "   - Applying log transformation and min-max scaling to non-stationary columns\n",
    "\n",
    "3. **Sequencing Data**:\n",
    "   - Custom `split_sequence` function to prepare data for LSTM\n",
    "   - Creates sequences of past data (e.g., 8 time steps) to predict future values\n",
    "\n",
    "4. **LSTM Network Structure**:\n",
    "   - Input dimensions, hidden dimensions, layer dimensions, and output dimensions\n",
    "   - LSTM layer followed by fully connected layers\n",
    "   - Initialization of hidden state and cell state\n",
    "\n",
    "5. **Training**:\n",
    "   - Using Mean Squared Error (MSE) loss for regression\n",
    "   - Adam optimizer\n",
    "   - Plotting loss over epochs to visualize training progress\n",
    "\n",
    "6. **Alternative Approaches**:\n",
    "   - Mentioned 1D Convolutional Neural Networks as an alternative to LSTM\n",
    "   - Classification approach using Binary Cross Entropy loss (not implemented in this example)\n",
    "\n",
    "7. **Limitations and Applications**:\n",
    "   - Author notes limited success with this type of analysis for market prediction\n",
    "   - Provides code structure for those interested in exploring LSTM with sequential data\n",
    "\n",
    "8. **Next Steps**:\n",
    "   - Moving on to reinforcement learning\n",
    "   - Future lessons on training an agent to trade, starting with a sine wave and progressing to Apple stock trading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e41454-5376-43a4-8934-24ad48e9d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl  # Using Polars for data management\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Statistics\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132b625-221a-447b-822d-1c805a512370",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ea91a6-5739-46ad-a1a9-68267cdae6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Open',\n",
       " 'Adj Close',\n",
       " 'Returns',\n",
       " 'Range',\n",
       " 'MA_12',\n",
       " 'MA_21',\n",
       " 'HMM',\n",
       " 'MA_Signal',\n",
       " 'HMM_Signal',\n",
       " 'Main_Signal',\n",
       " 'lrets_bench',\n",
       " 'bench_prod',\n",
       " 'bench_prod_exp',\n",
       " 'lrets_strat',\n",
       " 'lrets_prod',\n",
       " 'strat_prod_exp']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from saved file using Polars\n",
    "df = pl.read_csv(\"data/HMM-SPY.csv\")\n",
    "\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d29b9cf-4e67-4401-90ff-7880fab69a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Open</th><th>Adj Close</th><th>MA_12</th><th>MA_21</th><th>HMM</th><th>lrets_bench</th><th>lrets_strat</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>256.820007</td><td>242.321487</td><td>233.62229</td><td>238.259514</td><td>2</td><td>0.009351</td><td>0.0</td></tr><tr><td>257.559998</td><td>243.454041</td><td>234.584504</td><td>238.076622</td><td>3</td><td>0.004663</td><td>-0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌────────────┬────────────┬────────────┬────────────┬─────┬─────────────┬─────────────┐\n",
       "│ Open       ┆ Adj Close  ┆ MA_12      ┆ MA_21      ┆ HMM ┆ lrets_bench ┆ lrets_strat │\n",
       "│ ---        ┆ ---        ┆ ---        ┆ ---        ┆ --- ┆ ---         ┆ ---         │\n",
       "│ f64        ┆ f64        ┆ f64        ┆ f64        ┆ i64 ┆ f64         ┆ f64         │\n",
       "╞════════════╪════════════╪════════════╪════════════╪═════╪═════════════╪═════════════╡\n",
       "│ 256.820007 ┆ 242.321487 ┆ 233.62229  ┆ 238.259514 ┆ 2   ┆ 0.009351    ┆ 0.0         │\n",
       "│ 257.559998 ┆ 243.454041 ┆ 234.584504 ┆ 238.076622 ┆ 3   ┆ 0.004663    ┆ -0.0        │\n",
       "└────────────┴────────────┴────────────┴────────────┴─────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uf = df.clone()\n",
    "useful_features = [\"Open\", \"Adj Close\", \"MA_12\", \"MA_21\", \"HMM\", \"lrets_bench\", \"lrets_strat\"]\n",
    "df_uf = df.select(useful_features)\n",
    "\n",
    "df_uf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0be4984-ec61-4c7b-85d0-ac8a77e824e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Float64, Float64, Float64, Float64, Int64, Float64, Float64]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd6ad52-9a24-48ab-af88-1af820fbbbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Open</th><th>Adj Close</th><th>MA_12</th><th>MA_21</th><th>HMM</th><th>lrets_bench</th><th>lrets_strat</th><th>lrets_bench_roll</th><th>TARGET</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>264.820007</td><td>248.068802</td><td>244.6132</td><td>238.964305</td><td>1</td><td>-0.013603</td><td>-0.003063</td><td>0.003279</td><td>-0.000604</td></tr><tr><td>264.01001</td><td>248.587906</td><td>245.47986</td><td>239.758611</td><td>1</td><td>0.00209</td><td>-0.0</td><td>0.002553</td><td>-0.003063</td></tr><tr><td>263.209991</td><td>248.719986</td><td>246.201024</td><td>240.785478</td><td>2</td><td>0.000531</td><td>0.0</td><td>0.00214</td><td>-0.0</td></tr><tr><td>265.609985</td><td>250.824539</td><td>246.909612</td><td>242.198377</td><td>3</td><td>0.008426</td><td>-0.008393</td><td>0.00263</td><td>0.0</td></tr><tr><td>263.390015</td><td>248.918198</td><td>247.364958</td><td>242.988414</td><td>2</td><td>-0.007629</td><td>0.00201</td><td>0.001829</td><td>-0.008393</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ Open      ┆ Adj Close ┆ MA_12     ┆ MA_21     ┆ … ┆ lrets_ben ┆ lrets_str ┆ lrets_ben ┆ TARGET   │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ch        ┆ at        ┆ ch_roll   ┆ ---      │\n",
       "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 264.82000 ┆ 248.06880 ┆ 244.6132  ┆ 238.96430 ┆ … ┆ -0.013603 ┆ -0.003063 ┆ 0.003279  ┆ -0.00060 │\n",
       "│ 7         ┆ 2         ┆           ┆ 5         ┆   ┆           ┆           ┆           ┆ 4        │\n",
       "│ 264.01001 ┆ 248.58790 ┆ 245.47986 ┆ 239.75861 ┆ … ┆ 0.00209   ┆ -0.0      ┆ 0.002553  ┆ -0.00306 │\n",
       "│           ┆ 6         ┆           ┆ 1         ┆   ┆           ┆           ┆           ┆ 3        │\n",
       "│ 263.20999 ┆ 248.71998 ┆ 246.20102 ┆ 240.78547 ┆ … ┆ 0.000531  ┆ 0.0       ┆ 0.00214   ┆ -0.0     │\n",
       "│ 1         ┆ 6         ┆ 4         ┆ 8         ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 265.60998 ┆ 250.82453 ┆ 246.90961 ┆ 242.19837 ┆ … ┆ 0.008426  ┆ -0.008393 ┆ 0.00263   ┆ 0.0      │\n",
       "│ 5         ┆ 9         ┆ 2         ┆ 7         ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 263.39001 ┆ 248.91819 ┆ 247.36495 ┆ 242.98841 ┆ … ┆ -0.007629 ┆ 0.00201   ┆ 0.001829  ┆ -0.00839 │\n",
       "│ 5         ┆ 8         ┆ 8         ┆ 4         ┆   ┆           ┆           ┆           ┆ 3        │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Rolling Returns and TARGET\n",
    "# Compute the rolling mean for 'lrets_bench'\n",
    "df_uf = df_uf.with_columns(\n",
    "    pl.col(\"lrets_bench\").rolling_mean(window_size=10).alias(\"lrets_bench_roll\")\n",
    ")\n",
    "# Shift the 'lrets_strat' column to create the 'TARGET' column\n",
    "df_uf = df_uf.with_columns(\n",
    "    pl.col(\"lrets_strat\").shift(1).alias(\"TARGET\")\n",
    ")\n",
    "# Drop rows with null values\n",
    "df_uf = df_uf.drop_nulls()\n",
    "df_uf.head()\n",
    "# If we denote the log return at time t as r(t), then this operation is creating a target variable y(t) such that:\n",
    "# y(t) = r(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01cff9d7-c152-4693-8f15-c7a4d8f73a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Stationary Features Found: 4\n",
      "['Open', 'Adj Close', 'MA_12', 'MA_21']\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to check if a series is non-stationary\n",
    "def is_non_stationary(series):\n",
    "    # Remove NaN values from NumPy array\n",
    "    series = series[~np.isnan(series)]\n",
    "    if len(series) == 0:\n",
    "        return False  # Return False if series is empty after dropping nulls\n",
    "    dftest = adfuller(series)\n",
    "    p_value = dftest[1]\n",
    "    t_test = dftest[0] < dftest[4][\"1%\"]\n",
    "    # Return True if p-value > 0.05 or t-statistic doesn't exceed 1% critical value\n",
    "    return p_value > 0.05 or not t_test\n",
    "\n",
    "# Initialize list to store non-stationary column names\n",
    "non_stationaries = []\n",
    "\n",
    "# Iterate through each column in the dataframe\n",
    "for col in df_uf.columns:\n",
    "    series = df_uf[col].to_numpy()\n",
    "    if is_non_stationary(series):\n",
    "        non_stationaries.append(col)\n",
    "\n",
    "# Print results\n",
    "print(f\"Non-Stationary Features Found: {len(non_stationaries)}\")\n",
    "print(non_stationaries)\n",
    "\n",
    "# Trading Implications:\n",
    "# 1. Non-stationary features often include raw price levels, cumulative indicators, and some volatility measures.\n",
    "# 2. Stationary features are typically returns, oscillating indicators, and relative strength measures.\n",
    "# 3. Non-stationary features may require differencing or other transformations before use in many statistical models.\n",
    "# 4. Cointegration analysis often involves finding stationary relationships between non-stationary series.\n",
    "# 5. Mean-reversion strategies typically work better with stationary series.\n",
    "# 6. Trend-following strategies might utilize information from non-stationary series.\n",
    "# 7. Risk models and volatility forecasts may need adjustment when dealing with non-stationary data.\n",
    "# 8. Feature engineering might involve creating stationary features from non-stationary ones (e.g., price to moving average ratio).\n",
    "# 9. Some machine learning models (e.g., certain neural networks) can handle non-stationary data better than traditional statistical models.\n",
    "# 10. Always be cautious of spurious correlations when working with non-stationary financial time series.\n",
    "\n",
    "# Note: If results still differ from the pandas version, consider:\n",
    "# - Checking for data type differences between pandas and Polars columns\n",
    "# - Verifying that the data in both versions is identical\n",
    "# - Examining any preprocessing steps that might affect the stationarity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6911c8c5-507a-4d73-8ce4-a3d056bd7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Non-Stationary items to log\n",
    "df_uf[non_stationaries] = np.log(df_uf[non_stationaries])\n",
    "\n",
    "# Explanation:\n",
    "# 1. Purpose: This code applies a logarithmic transformation to the non-stationary features identified earlier.\n",
    "#\n",
    "# 2. Why use logarithmic transformation:\n",
    "#    - Helps stabilize variance in time series data\n",
    "#    - Can make multiplicative relationships additive\n",
    "#    - Often makes non-stationary data more stationary\n",
    "#    - Reduces the impact of large outliers\n",
    "#\n",
    "# 3. Financial implications:\n",
    "#    - Log prices: Represent relative (percentage) changes rather than absolute changes\n",
    "#    - Log-transformed moving averages: Reflect proportional rather than absolute price levels\n",
    "#\n",
    "# 4. Benefits for analysis:\n",
    "#    - May improve the performance of statistical models assuming stationarity\n",
    "#    - Can help in identifying trends and patterns that are not apparent in raw price data\n",
    "#    - Useful for comparing assets with different price scales\n",
    "#\n",
    "# 5. Interpretation:\n",
    "#    - Differences in log prices approximate percentage returns\n",
    "#    - Useful for calculating continuously compounded returns\n",
    "#\n",
    "# 6. Caution:\n",
    "#    - Ensure all values are positive before applying log transformation\n",
    "#    - Be aware that log transformation can affect the interpretation of your results\n",
    "#    - Some models may require you to reverse this transformation for final predictions\n",
    "#\n",
    "# 7. Alternative approaches:\n",
    "#    - Differencing: Another common method to induce stationarity\n",
    "#    - Percent change: Similar to log returns but easier to interpret\n",
    "#\n",
    "# 8. Next steps:\n",
    "#    - Re-test for stationarity after this transformation\n",
    "#    - Consider additional transformations if necessary (e.g., differencing of log prices)\n",
    "#    - Adjust your analysis and modeling techniques to work with log-transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae7615c-4a0c-4352-81be-99da90bbefb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 9)\n",
      "┌──────────┬───────────┬──────────┬──────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
      "│ Open     ┆ Adj Close ┆ MA_12    ┆ MA_21    ┆ … ┆ lrets_benc ┆ lrets_stra ┆ lrets_ben ┆ TARGET    │\n",
      "│ ---      ┆ ---       ┆ ---      ┆ ---      ┆   ┆ h          ┆ t          ┆ ch_roll   ┆ ---       │\n",
      "│ f64      ┆ f64       ┆ f64      ┆ f64      ┆   ┆ ---        ┆ ---        ┆ ---       ┆ f64       │\n",
      "│          ┆           ┆          ┆          ┆   ┆ f64        ┆ f64        ┆ f64       ┆           │\n",
      "╞══════════╪═══════════╪══════════╪══════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
      "│ 0.200641 ┆ 0.177745  ┆ 0.047211 ┆ 0.0      ┆ … ┆ 0.504813   ┆ 0.532233   ┆ 0.681136  ┆ -0.000604 │\n",
      "│ 0.196512 ┆ 0.180398  ┆ 0.052376 ┆ 0.004967 ┆ … ┆ 0.582264   ┆ 0.595795   ┆ 0.664534  ┆ -0.003063 │\n",
      "│ 0.192422 ┆ 0.181072  ┆ 0.056659 ┆ 0.011364 ┆ … ┆ 0.574569   ┆ 0.595795   ┆ 0.655088  ┆ -0.0      │\n",
      "│ 0.204655 ┆ 0.191766  ┆ 0.060856 ┆ 0.020121 ┆ … ┆ 0.613533   ┆ 0.421644   ┆ 0.666302  ┆ 0.0       │\n",
      "│ 0.193344 ┆ 0.182083  ┆ 0.063546 ┆ 0.024995 ┆ … ┆ 0.534293   ┆ 0.637505   ┆ 0.647975  ┆ -0.008393 │\n",
      "│ 0.196053 ┆ 0.180398  ┆ 0.065648 ┆ 0.029236 ┆ … ┆ 0.565394   ┆ 0.688358   ┆ 0.658932  ┆ 0.00201   │\n",
      "│ 0.202065 ┆ 0.200332  ┆ 0.069629 ┆ 0.034699 ┆ … ┆ 0.649466   ┆ 0.783571   ┆ 0.668788  ┆ 0.004461  │\n",
      "│ 0.214262 ┆ 0.21143   ┆ 0.075411 ┆ 0.040193 ┆ … ┆ 0.615104   ┆ 0.799558   ┆ 0.683255  ┆ 0.00905   │\n",
      "│ 0.227497 ┆ 0.21204   ┆ 0.079876 ┆ 0.04563  ┆ … ┆ 0.574323   ┆ 0.592722   ┆ 0.667074  ┆ 0.00982   │\n",
      "│ 0.227298 ┆ 0.220938  ┆ 0.084908 ┆ 0.053188 ┆ … ┆ 0.606549   ┆ 0.774013   ┆ 0.652873  ┆ -0.000148 │\n",
      "└──────────┴───────────┴──────────┴──────────┴───┴────────────┴────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Min Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max scaling to all columns except the last one\n",
    "scaled_data = scaler.fit_transform(df_uf.select(pl.all().exclude(df_uf.columns[-1])).to_numpy())\n",
    "\n",
    "# Create a new DataFrame with scaled data\n",
    "df_scaled = pl.DataFrame(scaled_data, schema=df_uf.columns[:-1])\n",
    "\n",
    "# Add back the last column (assuming it's the target variable)\n",
    "df_scaled = df_scaled.with_columns(df_uf.select(df_uf.columns[-1]))\n",
    "\n",
    "print(df_scaled.head(10))\n",
    "\n",
    "# Explanation:\n",
    "# 1. Purpose: This code applies Min-Max scaling to all features except the last column (typically the target variable).\n",
    "#\n",
    "# 2. Why use Min-Max scaling:\n",
    "#    - Normalizes features to a fixed range, typically [0, 1]\n",
    "#    - Preserves zero values and does not center the data\n",
    "#    - Useful when you need bounded intervals\n",
    "#\n",
    "# 3. Financial implications:\n",
    "#    - Helps compare features with different scales (e.g., price vs. volume)\n",
    "#    - Useful for algorithms sensitive to feature magnitudes (e.g., neural networks, k-nearest neighbors)\n",
    "#    - Can help in visualizing and comparing different financial indicators\n",
    "#\n",
    "# 4. Benefits for analysis:\n",
    "#    - Prevents features with larger magnitudes from dominating the analysis\n",
    "#    - Can improve the convergence of gradient descent algorithms\n",
    "#    - Useful for techniques that rely on distances between data points\n",
    "#\n",
    "# 5. Interpretation:\n",
    "#    - Scaled values represent the relative position within the feature's range\n",
    "#    - 0 represents the minimum value, 1 represents the maximum value\n",
    "#\n",
    "# 6. Caution:\n",
    "#    - Sensitive to outliers, as min and max values define the scaling\n",
    "#    - May not be suitable if the true min/max of a feature is unknown (e.g., in streaming data)\n",
    "#    - Can compress information in features with larger ranges\n",
    "#\n",
    "# 7. Alternative approaches:\n",
    "#    - StandardScaler: Scales to zero mean and unit variance\n",
    "#    - RobustScaler: Uses median and interquartile range, less sensitive to outliers\n",
    "#    - Normalization: Scaling individual samples to unit norm\n",
    "#\n",
    "# 8. Next steps:\n",
    "#    - Ensure to use the same scaler for transforming test/new data\n",
    "#    - Consider the impact of scaling on feature importance interpretation\n",
    "#    - Evaluate model performance with and without scaling to assess its impact\n",
    "#\n",
    "# 9. Note on implementation:\n",
    "#    - We exclude the last column assuming it's the target variable\n",
    "#    - Adjust the indexing if your target variable is in a different position\n",
    "#    - The scaler object should be saved to apply the same transformation to future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea4731a6-ee9e-495e-abbf-e764fd03357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data: \n",
      " [[0.20064088 0.1777452  0.0472111  0.         0.33333333 0.50481327\n",
      "  0.53223262 0.6811359 ]] \n",
      "\n",
      "y: \n",
      " [-0.00060402 -0.00306336 -0.          0.         -0.00839313] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# Split X and Y data\n",
    "X_data = df_scaled.select(pl.all().exclude(df_scaled.columns[-1])).to_numpy()\n",
    "y_data = df_scaled.select(df_scaled.columns[-1]).to_numpy().flatten()\n",
    "\n",
    "print(f\"X_data: \\n {X_data[:1]} \\n\")\n",
    "print(f\"y: \\n {y_data[0:5]} \\n\")\n",
    "\n",
    "# Explanation:\n",
    "# 1. Purpose: This code separates the feature variables (X_data) from the target variable (y_data).\n",
    "#\n",
    "# 2. Data Structure:\n",
    "#    - X_data: 2D numpy array containing all features (independent variables)\n",
    "#    - y_data: 1D numpy array containing the target variable (dependent variable)\n",
    "#\n",
    "# 3. Financial Implications:\n",
    "#    - X_data typically includes price levels, technical indicators, and other relevant features\n",
    "#    - y_data often represents the variable we're trying to predict (e.g., future returns, price movements)\n",
    "#\n",
    "# 4. Importance in Machine Learning:\n",
    "#    - This split is crucial for supervised learning tasks in finance\n",
    "#    - Allows models to learn relationships between features and the target variable\n",
    "#\n",
    "# 5. X_data (Features):\n",
    "#    - Each row represents a time point or observation\n",
    "#    - Each column represents a different feature or indicator\n",
    "#    - In finance, might include open/close prices, moving averages, volatility measures, etc.\n",
    "#\n",
    "# 6. y_data (Target):\n",
    "#    - Represents the variable we're aiming to predict\n",
    "#    - In trading, could be future price movements, returns, or trading signals\n",
    "#\n",
    "# 7. Data Handling:\n",
    "#    - Using Polars for efficient data manipulation\n",
    "#    - Converting to NumPy arrays for compatibility with most ML libraries\n",
    "#\n",
    "# 8. Considerations:\n",
    "#    - Ensure time-series integrity: X_data at time t should only include information available at or before t\n",
    "#    - Be cautious of look-ahead bias when preparing features and targets\n",
    "#\n",
    "# 9. Next Steps:\n",
    "#    - Further split this data into training and testing sets\n",
    "#    - Consider cross-validation strategies suitable for time-series data\n",
    "#    - Evaluate the need for any additional preprocessing or feature engineering\n",
    "#\n",
    "# 10. Note on Implementation:\n",
    "#     - Assumes the target variable is the last column in the DataFrame\n",
    "#     - Adjust indexing if your target variable is positioned differently\n",
    "#     - The `flatten()` method is used to ensure y_data is a 1D array, as required by most ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fca60-2dec-4336-8898-2a6f7ca9cb49",
   "metadata": {},
   "source": [
    "### Data Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8848800b-7684-4a49-ac80-3cd092b988a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "def split_sequence(input_data, n_steps):\n",
    "    \"\"\"\n",
    "    Split a multivariate time series into samples for sequence prediction.\n",
    "    \n",
    "    Args:\n",
    "    input_data (np.array): 2D NumPy array where each row is a time step and each column is a feature\n",
    "    n_steps (int): Number of time steps to use as input\n",
    "    \n",
    "    Returns:\n",
    "    np.array: 3D NumPy array of input sequences\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    for i in range(len(input_data) - n_steps + 1):\n",
    "        # Extract sequence of `n_steps` time steps for all features except the last column\n",
    "        seq_x = input_data[i:(i + n_steps), :-1]\n",
    "        X.append(seq_x)\n",
    "    return np.array(X)\n",
    "\n",
    "# Example usage (assuming df_scaled is your Polars DataFrame):\n",
    "# input_data = df_scaled.to_numpy()\n",
    "# X = split_sequence(input_data, n_steps=10)\n",
    "# print(f\"Shape of X: {X.shape}\")\n",
    "\n",
    "# Explanation:\n",
    "# 1. Purpose: This function prepares time series data for sequence-based models (e.g., LSTM, GRU).\n",
    "#\n",
    "# 2. Function Input:\n",
    "#    - input_data: Entire dataset including features and target\n",
    "#    - n_steps: The number of historical time steps to use as input (lookback period)\n",
    "#\n",
    "# 3. Function Output:\n",
    "#    - 3D NumPy array: (samples, time steps, features)\n",
    "#\n",
    "# 4. Financial Implications:\n",
    "#    - Allows models to learn from sequences of historical data\n",
    "#    - Crucial for capturing temporal dependencies in financial time series\n",
    "#\n",
    "# 5. Use in Trading:\n",
    "#    - Can be used to prepare data for predicting future price movements\n",
    "#    - Helps in developing models that consider recent market trends\n",
    "#\n",
    "# 6. Sliding Window Approach:\n",
    "#    - Creates overlapping sequences, moving one time step at a time\n",
    "#    - Maximizes the use of available data\n",
    "#\n",
    "# 7. Feature Handling:\n",
    "#    - Excludes the last column (assumed to be the target variable) from the input sequences\n",
    "#    - Ensures no future information leakage in the input features\n",
    "#\n",
    "# 8. Considerations:\n",
    "#    - Choose n_steps carefully: too short might miss important patterns, too long might introduce noise\n",
    "#    - Consider the frequency of your data when selecting n_steps (e.g., daily vs. hourly data)\n",
    "#\n",
    "# 9. Potential Enhancements:\n",
    "#    - Add option to include the target variable in the output for multi-step forecasting\n",
    "#    - Implement stride parameter for non-overlapping sequences if needed\n",
    "#\n",
    "# 10. Next Steps:\n",
    "#     - Prepare corresponding target values for each sequence\n",
    "#     - Split the resulting sequences into training and testing sets\n",
    "#     - Consider normalization within each sequence for certain types of models\n",
    "#\n",
    "# 11. Note on Implementation:\n",
    "#     - This function assumes a 2D NumPy array input, so convert your Polars DataFrame accordingly\n",
    "#     - Adjust the indexing if your target variable is not in the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfbbd028-d015-4e3a-8e1f-d51c8e528aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (836, 8, 7)\n",
      "Shape of y: (835,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Choose a number of time steps in each sample window\n",
    "n_timesteps = 8\n",
    "\n",
    "# Split X into sequence samples\n",
    "X = split_sequence(X_data, n_timesteps)\n",
    "\n",
    "# Adjust y to start at the right point\n",
    "y = y_data[n_timesteps:]\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# Explanation:\n",
    "# 1. Purpose: This code prepares the input features and target variable for sequence-based modeling.\n",
    "#\n",
    "# 2. Time Steps (n_timesteps):\n",
    "#    - Set to 8, meaning each input sequence will contain 8 historical time steps\n",
    "#    - In finance: Could represent 8 days, weeks, or any other time unit depending on data frequency\n",
    "#\n",
    "# 3. X Preparation:\n",
    "#    - Uses the split_sequence function to create overlapping sequences of input features\n",
    "#    - Results in a 3D array: (samples, time steps, features)\n",
    "#\n",
    "# 4. Y Adjustment:\n",
    "#    - Aligns the target variable with the input sequences\n",
    "#    - Starts from the n_timesteps index to match the end of each input sequence\n",
    "#\n",
    "# 5. Financial Implications:\n",
    "#    - Allows models to learn from recent historical patterns (last 8 time steps)\n",
    "#    - Crucial for capturing short-term trends and seasonality in financial data\n",
    "#\n",
    "# 6. Trading Strategy Considerations:\n",
    "#    - 8 time steps might represent a trading week (if using daily data) or two trading weeks\n",
    "#    - Adjust n_timesteps based on the believed relevant historical context for your trading strategy\n",
    "#\n",
    "# 7. Data Structure:\n",
    "#    - X: Each sample is a sequence of 8 time steps, each containing multiple features\n",
    "#    - y: Each value corresponds to the target variable for the time step immediately following its X sequence\n",
    "#\n",
    "# 8. Model Input Preparation:\n",
    "#    - Suitable for sequence models like LSTM, GRU, or 1D CNNs in PyTorch or TensorFlow\n",
    "#\n",
    "# 9. Potential Risks:\n",
    "#    - Ensure no data leakage: y values should not be included in their corresponding X sequences\n",
    "#    - Be aware of the trade-off: larger n_timesteps captures more history but reduces the number of training samples\n",
    "#\n",
    "# 10. Alternatives to Consider:\n",
    "#     - Variable-length sequences if different lookback periods are relevant for different market conditions\n",
    "#     - Multiple input sequences with different timesteps to capture both short and long-term patterns\n",
    "#\n",
    "# 11. Next Steps:\n",
    "#     - Split X and y into training and testing sets\n",
    "#     - Consider additional feature engineering within each sequence\n",
    "#     - Normalize or standardize data within each sequence if required by your model\n",
    "#\n",
    "# 12. Validation:\n",
    "#     - Ensure X.shape[0] == y.shape[0] to confirm alignment\n",
    "#     - Verify that the first y value corresponds to the target for the last time step of the first X sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acffa1a1-2ead-4f66-ae35-de96f7016711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X summary:\n",
      "Sequence 1:\n",
      "[[0.20064088 0.1777452  0.0472111  0.         0.33333333 0.50481327\n",
      "  0.53223262]\n",
      " [0.19651226 0.1803982  0.05237563 0.00496689 0.33333333 0.58226423\n",
      "  0.59579465]\n",
      " [0.19242205 0.18107234 0.05665925 0.01136369 0.66666667 0.57456887\n",
      "  0.59579465]\n",
      " [0.20465531 0.191766   0.06085597 0.02012078 1.         0.61353273\n",
      "  0.42164448]\n",
      " [0.19334353 0.18208334 0.06354648 0.02499517 0.66666667 0.53429341\n",
      "  0.63750451]\n",
      " [0.19605276 0.1803982  0.06564806 0.02923554 0.66666667 0.56539409\n",
      "  0.68835771]\n",
      " [0.20206512 0.20033197 0.06962947 0.0346993  1.         0.64946563\n",
      "  0.7835711 ]\n",
      " [0.21426199 0.21142959 0.07541099 0.04019253 0.66666667 0.61510364\n",
      "  0.79955837]]\n",
      "\n",
      "Sequence 2:\n",
      "[[0.19651226 0.1803982  0.05237563 0.00496689 0.33333333 0.58226423\n",
      "  0.59579465]\n",
      " [0.19242205 0.18107234 0.05665925 0.01136369 0.66666667 0.57456887\n",
      "  0.59579465]\n",
      " [0.20465531 0.191766   0.06085597 0.02012078 1.         0.61353273\n",
      "  0.42164448]\n",
      " [0.19334353 0.18208334 0.06354648 0.02499517 0.66666667 0.53429341\n",
      "  0.63750451]\n",
      " [0.19605276 0.1803982  0.06564806 0.02923554 0.66666667 0.56539409\n",
      "  0.68835771]\n",
      " [0.20206512 0.20033197 0.06962947 0.0346993  1.         0.64946563\n",
      "  0.7835711 ]\n",
      " [0.21426199 0.21142959 0.07541099 0.04019253 0.66666667 0.61510364\n",
      "  0.79955837]\n",
      " [0.2274973  0.21204049 0.07987561 0.04563017 1.         0.57432295\n",
      "  0.59272153]]\n",
      "\n",
      "\n",
      "y summary:\n",
      "Target 1: 0.009820352376471048\n",
      "Target 2: -0.00014810849047420204\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Summarize and check the X sequence\n",
    "print(\"\\nX summary:\")\n",
    "for i in range(min(2, len(X))):\n",
    "    print(f\"Sequence {i+1}:\")\n",
    "    print(X[i])\n",
    "    print()\n",
    "\n",
    "# Summarize and check the y sequence\n",
    "print(\"\\ny summary:\")\n",
    "for i in range(min(2, len(y))):\n",
    "    print(f\"Target {i+1}: {y[i]}\")\n",
    "\n",
    "# Explanation:\n",
    "# 1. Purpose: This code provides a visual inspection of the prepared X sequences and y targets.\n",
    "#\n",
    "# 2. X Sequence Visualization:\n",
    "#    - Displays the first two sequences from X\n",
    "#    - Each sequence represents 8 time steps (as set by n_timesteps)\n",
    "#    - Each time step contains multiple features\n",
    "#\n",
    "# 3. Y Target Visualization:\n",
    "#    - Shows the first two target values from y\n",
    "#    - Each value corresponds to the target variable for the time step following its X sequence\n",
    "#\n",
    "# 4. Financial Data Interpretation:\n",
    "#    - X sequences: Represent historical patterns of financial indicators\n",
    "#    - y values: Typically represent future price movements or returns\n",
    "#\n",
    "# 5. Sequence Structure:\n",
    "#    - Each row in X represents a time step\n",
    "#    - Each column represents a different feature (e.g., price, volume, technical indicators)\n",
    "#\n",
    "# 6. Data Alignment Check:\n",
    "#    - Ensures that X sequences and y targets are properly aligned\n",
    "#    - Critical for accurate model training and prediction\n",
    "#\n",
    "# 7. Feature Identification:\n",
    "#    - Allows for quick verification of included features\n",
    "#    - Helps in identifying any anomalies or unexpected values\n",
    "#\n",
    "# 8. Scale Inspection:\n",
    "#    - If data is normalized/scaled, values should typically be between 0 and 1\n",
    "#    - Helps in verifying the effectiveness of previous preprocessing steps\n",
    "#\n",
    "# 9. Temporal Relationship:\n",
    "#    - The last row of each X sequence should immediately precede its corresponding y value\n",
    "#    - Crucial for maintaining the temporal integrity of the time series\n",
    "#\n",
    "# 10. Model Input Verification:\n",
    "#     - Confirms that the data is in the correct format for sequence models (e.g., LSTM, GRU)\n",
    "#     - 3D structure of X: (samples, time steps, features)\n",
    "#\n",
    "# 11. Potential Red Flags:\n",
    "#     - Unexpected feature values or ranges\n",
    "#     - Misalignment between X sequences and y targets\n",
    "#     - Inconsistent number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e138fe0-5d50-43c0-821b-66fdee1603e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.length = self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "# Trainset\n",
    "trainset = dataset(X, y)\n",
    "\n",
    "# Data Loader\n",
    "trainloader = DataLoader(trainset, batch_size=20, shuffle=False, drop_last=True) \n",
    "\n",
    "# Explanation:\n",
    "# 1. Purpose: This code creates a custom PyTorch Dataset and DataLoader for efficient handling of financial time series data.\n",
    "#\n",
    "# 2. Custom Dataset Class:\n",
    "#    - Inherits from torch.utils.data.Dataset\n",
    "#    - Converts NumPy arrays to PyTorch tensors\n",
    "#    - Provides methods for accessing data and determining dataset size\n",
    "#\n",
    "# 3. Data Types:\n",
    "#    - Uses torch.float32 for both X and y\n",
    "#    - Ensures compatibility with PyTorch models and operations\n",
    "#\n",
    "# 4. Financial Data Handling:\n",
    "#    - X: 3D tensor (samples, time_steps, features) for sequence data\n",
    "#    - y: 1D tensor of target values\n",
    "#\n",
    "# 5. DataLoader Creation:\n",
    "#    - Batch size of 20: Processes 20 sequences at a time\n",
    "#    - shuffle=False: Maintains temporal order, crucial for time series data\n",
    "#\n",
    "# 6. Implications for Financial Modeling:\n",
    "#    - Enables efficient batch processing of financial time series\n",
    "#    - Preserves the temporal structure of the data\n",
    "#    - Facilitates training of deep learning models (e.g., LSTM, GRU) on financial data\n",
    "#\n",
    "# 7. Batch Size Considerations:\n",
    "#    - 20 sequences per batch balances between computational efficiency and granularity\n",
    "#    - May need adjustment based on model complexity and available computational resources\n",
    "#\n",
    "# 8. No Shuffling:\n",
    "#    - Maintains the chronological order of financial data\n",
    "#    - Important for capturing time-dependent patterns in markets\n",
    "#\n",
    "# 9. Memory Management:\n",
    "#    - Converts entire dataset to tensors at initialization\n",
    "#    - Efficient for smaller datasets, may need modification for very large financial datasets\n",
    "#\n",
    "# 10. Flexibility:\n",
    "#     - Easy to extend for including additional financial indicators or features\n",
    "#     - Can be modified to handle multiple input sequences or output targets\n",
    "#\n",
    "# 11. Potential Enhancements:\n",
    "#     - Add data normalization within the Dataset class if not done previously\n",
    "#     - Implement on-the-fly data augmentation techniques specific to financial data\n",
    "#\n",
    "# 12. Usage in Training Loop:\n",
    "#     - Allows easy iteration over batches of financial data during model training\n",
    "#     - Facilitates implementation of mini-batch gradient descent\n",
    "#\n",
    "# 13. Considerations for Production:\n",
    "#     - May need to implement real-time data feeding for live trading scenarios\n",
    "#     - Consider adding functionality for handling out-of-sample data or walk-forward testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d9f461-1723-4abb-a75d-bcb832bf3e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([836, 8, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2006, 0.1777, 0.0472, 0.0000, 0.3333, 0.5048, 0.5322],\n",
       "         [0.1965, 0.1804, 0.0524, 0.0050, 0.3333, 0.5823, 0.5958],\n",
       "         [0.1924, 0.1811, 0.0567, 0.0114, 0.6667, 0.5746, 0.5958],\n",
       "         [0.2047, 0.1918, 0.0609, 0.0201, 1.0000, 0.6135, 0.4216],\n",
       "         [0.1933, 0.1821, 0.0635, 0.0250, 0.6667, 0.5343, 0.6375],\n",
       "         [0.1961, 0.1804, 0.0656, 0.0292, 0.6667, 0.5654, 0.6884],\n",
       "         [0.2021, 0.2003, 0.0696, 0.0347, 1.0000, 0.6495, 0.7836],\n",
       "         [0.2143, 0.2114, 0.0754, 0.0402, 0.6667, 0.6151, 0.7996]],\n",
       "\n",
       "        [[0.1965, 0.1804, 0.0524, 0.0050, 0.3333, 0.5823, 0.5958],\n",
       "         [0.1924, 0.1811, 0.0567, 0.0114, 0.6667, 0.5746, 0.5958],\n",
       "         [0.2047, 0.1918, 0.0609, 0.0201, 1.0000, 0.6135, 0.4216],\n",
       "         [0.1933, 0.1821, 0.0635, 0.0250, 0.6667, 0.5343, 0.6375],\n",
       "         [0.1961, 0.1804, 0.0656, 0.0292, 0.6667, 0.5654, 0.6884],\n",
       "         [0.2021, 0.2003, 0.0696, 0.0347, 1.0000, 0.6495, 0.7836],\n",
       "         [0.2143, 0.2114, 0.0754, 0.0402, 0.6667, 0.6151, 0.7996],\n",
       "         [0.2275, 0.2120, 0.0799, 0.0456, 1.0000, 0.5743, 0.5927]],\n",
       "\n",
       "        [[0.1924, 0.1811, 0.0567, 0.0114, 0.6667, 0.5746, 0.5958],\n",
       "         [0.2047, 0.1918, 0.0609, 0.0201, 1.0000, 0.6135, 0.4216],\n",
       "         [0.1933, 0.1821, 0.0635, 0.0250, 0.6667, 0.5343, 0.6375],\n",
       "         [0.1961, 0.1804, 0.0656, 0.0292, 0.6667, 0.5654, 0.6884],\n",
       "         [0.2021, 0.2003, 0.0696, 0.0347, 1.0000, 0.6495, 0.7836],\n",
       "         [0.2143, 0.2114, 0.0754, 0.0402, 0.6667, 0.6151, 0.7996],\n",
       "         [0.2275, 0.2120, 0.0799, 0.0456, 1.0000, 0.5743, 0.5927],\n",
       "         [0.2273, 0.2209, 0.0849, 0.0532, 0.6667, 0.6065, 0.7740]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset.X.shape)\n",
    "trainset.X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c6405aa-b1e4-4edd-8c38-e8da2b71c9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0098, -0.0001,  0.0086,  0.0013, -0.0068, -0.0081,  0.0000,  0.0045,\n",
       "         0.0095, -0.0046])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45656b-f0c1-4fbe-8460-a183f9c93795",
   "metadata": {},
   "source": [
    "### Construct Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63622913-9915-4a81-8ad0-f380e554752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class LSTM_Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTM_Net, self).__init__()\n",
    "        \n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(hidden_dim, 5)\n",
    "\n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(5, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "                            \n",
    "        # Initialize Hidden State with zeros (layer dim = 1, x.size = 64)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "                            \n",
    "        # Initialize Cell State with zeros\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "#         # Outputs - Classification\n",
    "#         out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "#         out = self.fc1(out[:, -1, :])\n",
    "#         out = torch.sigmoid(self.fc2(out))\n",
    "\n",
    "        # Regression - Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h0, c0))\n",
    "        h_out = h_out.view(-1, self.hidden_dim)\n",
    "        out = self.fc1(h_out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Explanation:\n",
    "# 1. Purpose: This code defines an LSTM (Long Short-Term Memory) neural network for financial time series regression.\n",
    "#\n",
    "# 2. Network Architecture:\n",
    "#    - LSTM layer: Captures temporal dependencies in financial data\n",
    "#    - Two fully connected layers: For final prediction refinement\n",
    "#\n",
    "# 3. LSTM Layer:\n",
    "#    - input_dim: Number of features in each time step\n",
    "#    - hidden_dim: Size of the LSTM's hidden state\n",
    "#    - layer_dim: Number of LSTM layers\n",
    "#    - batch_first=True: Expects input shape (batch, seq_len, features)\n",
    "#\n",
    "# 4. Fully Connected Layers:\n",
    "#    - fc1: Reduces dimensionality to 5 nodes\n",
    "#    - fc2: Produces final output (typically 1 for regression tasks)\n",
    "#\n",
    "# 5. Forward Pass:\n",
    "#    - Initializes hidden and cell states with zeros\n",
    "#    - Processes the entire sequence through LSTM\n",
    "#    - Uses only the final hidden state for prediction\n",
    "#\n",
    "# 6. Financial Modeling Implications:\n",
    "#    - Suitable for predicting continuous values (e.g., prices, returns)\n",
    "#    - Can capture complex temporal patterns in financial time series\n",
    "#    - Flexible for various prediction horizons (adjust input sequence length)\n",
    "#\n",
    "# 7. Potential Applications:\n",
    "#    - Price forecasting\n",
    "#    - Volatility prediction\n",
    "#    - Risk assessment\n",
    "#    - Trading signal generation\n",
    "#\n",
    "# 8. Model Flexibility:\n",
    "#    - Can be easily adapted for classification tasks (e.g., trend direction)\n",
    "#    - Commented-out section shows potential modification for classification\n",
    "#\n",
    "# 9. Considerations:\n",
    "#    - LSTM complexity: Balance between model capacity and overfitting risk\n",
    "#    - Sequence length: Affects the temporal context considered for predictions\n",
    "#    - Hidden dimension: Impacts model's ability to capture complex patterns\n",
    "#\n",
    "# 10. Hyperparameter Tuning:\n",
    "#     - Adjust hidden_dim, layer_dim for optimal performance\n",
    "#     - Consider adding dropout for regularization\n",
    "#\n",
    "# 11. Training Considerations:\n",
    "#     - May require significant data and careful regularization\n",
    "#     - Consider using techniques like teacher forcing for stable training\n",
    "#\n",
    "# 12. Limitations:\n",
    "#     - May struggle with very long-term dependencies\n",
    "#     - Sensitive to scaling of input features\n",
    "#\n",
    "# 13. Enhancements:\n",
    "#     - Add attention mechanism for interpretability\n",
    "#     - Implement bidirectional LSTM for utilizing future context (in backtesting scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1832b4b8-f8a5-4cbb-87df-874be4a884a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: 8\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "input_dim = X.shape[2]\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 1\n",
    "model = LSTM_Net(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "print(f\"Model Parameters: {len(list(model.parameters()))}\")\n",
    "\n",
    "# Explanation:\n",
    "# 1. Purpose: This code initializes the LSTM model with specific dimensions tailored to the financial data.\n",
    "#\n",
    "# 2. Model Dimensions:\n",
    "#    - input_dim: Automatically set to the number of features in each time step (X.shape[2])\n",
    "#    - hidden_dim: Set to 100, determining the complexity of patterns the LSTM can capture\n",
    "#    - layer_dim: Set to 1, indicating a single LSTM layer\n",
    "#    - output_dim: Set to 1, suitable for single-value regression (e.g., price prediction)\n",
    "#\n",
    "# 3. Input Dimension (input_dim):\n",
    "#    - Derived from X.shape[2], ensuring compatibility with the prepared data\n",
    "#    - Represents the number of financial features or indicators used in each time step\n",
    "#\n",
    "# 4. Hidden Dimension (hidden_dim = 100):\n",
    "#    - Determines the size of the LSTM's hidden state\n",
    "#    - Impacts the model's capacity to capture complex financial patterns\n",
    "#    - Trade-off: Larger values increase model capacity but risk overfitting\n",
    "#\n",
    "# 5. Layer Dimension (layer_dim = 1):\n",
    "#    - Single LSTM layer, suitable for many financial prediction tasks\n",
    "#    - Can be increased for more complex temporal dependencies, at the cost of increased computation\n",
    "#\n",
    "# 6. Output Dimension (output_dim = 1):\n",
    "#    - Set for single-value regression, typical in financial forecasting\n",
    "#    - Examples: predicting next day's price, return, or volatility\n",
    "#\n",
    "# 7. Model Instantiation:\n",
    "#    - Creates an instance of the LSTM_Net class with the specified dimensions\n",
    "#\n",
    "# 8. Model Parameter Count:\n",
    "#    - Prints the number of trainable parameters in the model\n",
    "#    - Indicator of model complexity and potential for overfitting\n",
    "#\n",
    "# 9. Financial Modeling Implications:\n",
    "#    - Model structure suitable for various financial prediction tasks\n",
    "#    - Flexibility to handle multiple input features (technical indicators, market data)\n",
    "#    - Single output focused on one target variable at a time\n",
    "#\n",
    "# 10. Considerations for Financial Applications:\n",
    "#     - Adjust hidden_dim based on data complexity and available training data\n",
    "#     - Consider increasing layer_dim for very complex financial time series\n",
    "#     - Ensure input_dim matches the number of relevant financial indicators used\n",
    "#\n",
    "# 11. Potential Enhancements:\n",
    "#     - Experiment with different hidden_dim values to optimize performance\n",
    "#     - Consider adding more LSTM layers for complex financial data\n",
    "#     - Implement dropout or regularization techniques to prevent overfitting\n",
    "#\n",
    "# 12. Model Capacity vs. Data Size:\n",
    "#     - Ensure the model's capacity (determined by hidden_dim and layer_dim) is appropriate for your dataset size\n",
    "#     - Too large capacity might lead to overfitting, especially with limited financial data\n",
    "#\n",
    "# 13. Interpretability:\n",
    "#     - While powerful, LSTM models can be black boxes. Consider techniques like attention mechanisms for better interpretability in financial contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6415a94f-d700-4de5-8534-73d8209f8c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 7])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([5, 100])\n",
      "torch.Size([5])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Review Model Structure\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f34efd-c185-4e68-8822-651b472baf60",
   "metadata": {},
   "source": [
    "### Train LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "574fb2c8-93aa-4b1e-af44-41486019e935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.407182708135224e-06\n",
      "Loss: 7.062994882289786e-06\n",
      "Loss: 1.576198656039196e-06\n",
      "Loss: 1.2261634765309282e-05\n",
      "Loss: 3.342598517974693e-07\n",
      "Loss: 3.5728949114854913e-06\n",
      "Loss: 1.0855494110728614e-05\n",
      "Loss: 2.495409262337489e-06\n",
      "Loss: 8.300741001221468e-07\n",
      "Loss: 2.113051959895529e-05\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "# # for classification\n",
    "# criterion = nn.BCELoss() \n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-1)\n",
    "\n",
    "# Regression\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-1)\n",
    "\n",
    "losses = []\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, (X_train, y_train) in enumerate(trainloader):\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, y_train.unsqueeze(dim=1))\n",
    "                       \n",
    "        # Backward propegation\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Increment iteration\n",
    "        iter += 1\n",
    "        \n",
    "    # Track progress\n",
    "    if iter % 100 == 0:\n",
    "        print(f\"Loss: {loss}\")\n",
    "        losses.append(loss.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "176d0885-6300-4da7-af7b-76f724c8c712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review losses\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ca67e-ff15-4431-8d72-1afba00dc6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699bdd1-ffd9-44a4-9ec9-21ac6d76476e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
